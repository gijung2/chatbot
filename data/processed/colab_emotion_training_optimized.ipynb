{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¯ ê°ì • ë¶„ì„ ëª¨ë¸ ìµœì í™”: KoBERT íŒŒì¸íŠœë‹\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **KoBERT ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸**ì„ ìµœê³  ì„±ëŠ¥ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” íŠ¹ì§•\n",
        "- âœ… **ë°ì´í„° í’ˆì§ˆ ê°œì„ **: ë¶ˆê· í˜• í•´ì†Œ, ì „ì²˜ë¦¬ ìµœì í™”\n",
        "- âœ… **KoBERT íŒŒì¸íŠœë‹**: í•œêµ­ì–´ ì‚¬ì „í•™ìŠµ ëª¨ë¸ í™œìš©\n",
        "- âœ… **K-Fold êµì°¨ ê²€ì¦**: ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\n",
        "- âœ… **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ìµœì  í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸° ë“±\n",
        "- âœ… **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì¶”ì \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "# ì˜ì¡´ì„± ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ í˜¸í™˜ë˜ëŠ” ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜\n",
        "!pip install --upgrade pip -q\n",
        "!pip install transformers>=4.40.0 -q\n",
        "!pip install huggingface-hub>=0.20.0 -q\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
        "!pip install datasets accelerate -q\n",
        "!pip install scikit-learn imbalanced-learn -q\n",
        "!pip install pandas numpy matplotlib seaborn -q\n",
        "!pip install tqdm -q\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ë¨¸ì‹ ëŸ¬ë‹\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# ë”¥ëŸ¬ë‹\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset as HFDataset\n",
        "\n",
        "# ì§„í–‰ìƒí™© í‘œì‹œ\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ”¥ PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"ğŸ’» CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# transformers ë²„ì „ í™•ì¸\n",
        "try:\n",
        "    import transformers\n",
        "    print(f\"ğŸ“¦ Transformers ë²„ì „: {transformers.__version__}\")\n",
        "except:\n",
        "    print(\"âš ï¸ Transformers ë²„ì „ í™•ì¸ ì‹¤íŒ¨\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ 3. ì„¤ì • (Configuration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== ëª¨ë¸ ì„¤ì • ==========\n",
        "MODEL_NAME = \"monologg/kobert\"  # KoBERT ëª¨ë¸\n",
        "# ë‹¤ë¥¸ ì˜µì…˜: \"monologg/koelectra-base-v3-discriminator\" (KoELECTRA)\n",
        "\n",
        "# ========== ë°ì´í„° ì„¤ì • ==========\n",
        "DATA_PATH = \"/content/emotion_corpus_with_kote.csv\"  # Colabì— ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ\n",
        "MAX_LENGTH = 128  # ìµœëŒ€ í† í° ê¸¸ì´ (BERTëŠ” ë³´í†µ 128 ë˜ëŠ” 512)\n",
        "\n",
        "# ========== í•™ìŠµ ì„¤ì • ==========\n",
        "LEARNING_RATE = 2e-5  # íŒŒì¸íŠœë‹ìš© ë‚®ì€ í•™ìŠµë¥  (2e-5 ~ 5e-5 ê¶Œì¥)\n",
        "BATCH_SIZE = 16  # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì • (16, 32, 64 ë“±)\n",
        "NUM_EPOCHS = 5  # ì—í¬í¬ ìˆ˜ (ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ 3-5 ê¶Œì¥)\n",
        "WEIGHT_DECAY = 0.01  # ì •ê·œí™”\n",
        "WARMUP_STEPS = 500  # ì›Œë°ì—… ìŠ¤í…\n",
        "\n",
        "# ========== K-Fold ì„¤ì • ==========\n",
        "N_FOLDS = 5  # K-Fold êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜\n",
        "RANDOM_SEED = 42  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ\n",
        "\n",
        "# ========== ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ ì„¤ì • ==========\n",
        "USE_SAMPLING = True  # ìƒ˜í”Œë§ ì‚¬ìš© ì—¬ë¶€\n",
        "SAMPLING_STRATEGY = \"balanced\"  # 'balanced', 'minority', ë˜ëŠ” ë¹„ìœ¨ ì§€ì •\n",
        "\n",
        "# ========== ê°ì • í´ë˜ìŠ¤ ë§¤í•‘ ==========\n",
        "LABEL2ID = {'joy': 0, 'sad': 1, 'anxiety': 2, 'anger': 3, 'neutral': 4}\n",
        "ID2LABEL = {v: k for k, v in LABEL2ID.items()}\n",
        "NUM_LABELS = len(LABEL2ID)\n",
        "\n",
        "print(\"âœ… ì„¤ì • ì™„ë£Œ!\")\n",
        "print(f\"ğŸ“Š ëª¨ë¸: {MODEL_NAME}\")\n",
        "print(f\"ğŸ“ ìµœëŒ€ ê¸¸ì´: {MAX_LENGTH}\")\n",
        "print(f\"ğŸ¯ í•™ìŠµë¥ : {LEARNING_RATE}\")\n",
        "print(f\"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")\n",
        "print(f\"ğŸ”„ ì—í¬í¬: {NUM_EPOCHS}\")\n",
        "print(f\"ğŸ”€ K-Fold: {N_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¤ 4. ë°ì´í„° ì—…ë¡œë“œ\n",
        "\n",
        "**Colabì—ì„œ ì‹¤í–‰ ì‹œ**: ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë¡œì»¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# íŒŒì¼ ì—…ë¡œë“œ (Colabì—ì„œë§Œ ì‹¤í–‰)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ì—…ë¡œë“œëœ íŒŒì¼ëª… í™•ì¸\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
        "    # íŒŒì¼ëª…ì„ emotion_corpus_with_kote.csvë¡œ ë³€ê²½ (ì„ íƒì‚¬í•­)\n",
        "    if filename != \"emotion_corpus_with_kote.csv\":\n",
        "        os.rename(filename, \"emotion_corpus_with_kote.csv\")\n",
        "        print(f\"   â†’ emotion_corpus_with_kote.csvë¡œ ì´ë¦„ ë³€ê²½\")\n",
        "\n",
        "DATA_PATH = \"/content/emotion_corpus_with_kote.csv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§¹ 5. ë°ì´í„° ì „ì²˜ë¦¬ ë° í’ˆì§ˆ ê°œì„ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜\n",
        "    - HTML íƒœê·¸ ì œê±°\n",
        "    - URL ì œê±°\n",
        "    - ì´ë©”ì¼ ì œê±°\n",
        "    - ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text)\n",
        "    \n",
        "    # HTML íƒœê·¸ ì œê±°\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    \n",
        "    # URL ì œê±°\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    \n",
        "    # ì´ë©”ì¼ ì œê±°\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    \n",
        "    # ì‚¬ìš©ì ì•„ì´ë”” ì œê±° (ì˜ˆ: @username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    \n",
        "    # ì—°ì†ëœ ê³µë°± ì œê±°\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # ì•ë’¤ ê³µë°± ì œê±°\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "def normalize_emoticons(text: str) -> str:\n",
        "    \"\"\"\n",
        "    ì´ëª¨í‹°ì½˜ ì •ê·œí™”\n",
        "    - 'ã…‹ã…‹', 'ã…ã…' ê°œìˆ˜ì— ë”°ë¼ ê°ì •ë„ í‘œí˜„\n",
        "    - 'ã… ã… ', 'ã…œã…œ' ìŠ¬í”” í‘œí˜„\n",
        "    \"\"\"\n",
        "    # ê¸ì • ì´ëª¨í‹°ì½˜ (3ê°œ ì´ìƒì€ ê°•í•œ ê¸ì •)\n",
        "    text = re.sub(r'ã…‹{3,}', '[ê°•í•œê¸ì •]', text)\n",
        "    text = re.sub(r'ã…{3,}', '[ê°•í•œê¸ì •]', text)\n",
        "    text = re.sub(r'ã…‹{1,2}', '[ê¸ì •]', text)\n",
        "    text = re.sub(r'ã…{1,2}', '[ê¸ì •]', text)\n",
        "    \n",
        "    # ìŠ¬í”” ì´ëª¨í‹°ì½˜\n",
        "    text = re.sub(r'ã… {2,}', '[ìŠ¬í””]', text)\n",
        "    text = re.sub(r'ã…œ{2,}', '[ìŠ¬í””]', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    print(f\"   âœ… ì›ë³¸ ë°ì´í„°: {len(df):,}ê°œ ìƒ˜í”Œ\")\n",
        "    \n",
        "    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "    required_cols = ['text', 'emotion', 'label_id']\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}\")\n",
        "    \n",
        "    # í…ìŠ¤íŠ¸ ì •ì œ\n",
        "    print(\"\\nğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ì¤‘...\")\n",
        "    df['text'] = df['text'].apply(clean_text)\n",
        "    df['text'] = df['text'].apply(normalize_emoticons)\n",
        "    \n",
        "    # ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°\n",
        "    before_len = len(df)\n",
        "    df = df[df['text'].str.len() > 0].copy()\n",
        "    after_len = len(df)\n",
        "    print(f\"   âœ… ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°: {before_len - after_len}ê°œ ìƒ˜í”Œ ì œê±°\")\n",
        "    \n",
        "    # label_idê°€ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬\n",
        "    if df['label_id'].dtype == 'object':\n",
        "        # emotion ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ label_id ìƒì„±\n",
        "        df['label_id'] = df['emotion'].map(LABEL2ID)\n",
        "    \n",
        "    # NaN ì œê±°\n",
        "    df = df.dropna(subset=['text', 'emotion', 'label_id']).copy()\n",
        "    \n",
        "    # label_idë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
        "    df['label_id'] = df['label_id'].astype(int)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„°: {len(df):,}ê°œ ìƒ˜í”Œ\")\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "df = load_and_preprocess_data(DATA_PATH)\n",
        "\n",
        "# ê°ì • ë¶„í¬ í™•ì¸\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š ê°ì • ë¶„í¬\")\n",
        "print(\"=\"*60)\n",
        "emotion_counts = df['emotion'].value_counts()\n",
        "for emotion, count in emotion_counts.items():\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"{emotion:10s}: {count:6,}ê°œ ({percentage:5.2f}%)\")\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(10, 6))\n",
        "emotion_counts.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'])\n",
        "plt.title('ê°ì • ë¶„í¬', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('ê°ì •', fontsize=12)\n",
        "plt.ylabel('ìƒ˜í”Œ ìˆ˜', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš–ï¸ 6. ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def balance_dataset(df: pd.DataFrame, strategy: str = \"balanced\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ\n",
        "    \n",
        "    Args:\n",
        "        df: ë°ì´í„°í”„ë ˆì„\n",
        "        strategy: 'balanced' (ê· í˜•), 'minority' (ì†Œìˆ˜ í´ë˜ìŠ¤ ê¸°ì¤€), 'majority' (ë‹¤ìˆ˜ í´ë˜ìŠ¤ ê¸°ì¤€), ë˜ëŠ” ë¹„ìœ¨ ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "    print(\"\\nâš–ï¸ ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ ì¤‘...\")\n",
        "    \n",
        "    # í˜„ì¬ ë¶„í¬\n",
        "    print(\"\\nğŸ“Š ìƒ˜í”Œë§ ì „ ë¶„í¬:\")\n",
        "    before_counts = df['label_id'].value_counts().sort_index()\n",
        "    for label_id, count in before_counts.items():\n",
        "        emotion = ID2LABEL[label_id]\n",
        "        print(f\"   {emotion:10s} (ID {label_id}): {count:6,}ê°œ\")\n",
        "    \n",
        "    # ê°€ì¥ ì ì€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ í™•ì¸\n",
        "    min_samples = before_counts.min()\n",
        "    max_samples = before_counts.max()\n",
        "    mean_samples = int(before_counts.mean())\n",
        "    \n",
        "    print(f\"\\n   ìµœì†Œ: {min_samples:,}ê°œ, ìµœëŒ€: {max_samples:,}ê°œ, í‰ê· : {mean_samples:,}ê°œ\")\n",
        "    print(f\"   ë¶ˆê· í˜• ë¹„ìœ¨: {max_samples/min_samples:.2f}:1\")\n",
        "    \n",
        "    # ìƒ˜í”Œë§ ì „ëµ ì„¤ì •\n",
        "    if strategy == \"balanced\":\n",
        "        # í‰ê· ë³´ë‹¤ ì ì€ í´ë˜ìŠ¤ë§Œ í‰ê· ìœ¼ë¡œ ë§ì¶¤ (ì˜¤ë²„ìƒ˜í”Œë§ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ)\n",
        "        # í‰ê· ë³´ë‹¤ ë§ì€ í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "        sampling_strategy = {}\n",
        "        for label_id, count in before_counts.items():\n",
        "            if count < mean_samples:\n",
        "                # í‰ê· ë³´ë‹¤ ì ìœ¼ë©´ í‰ê· ìœ¼ë¡œ ë§ì¶¤\n",
        "                sampling_strategy[label_id] = mean_samples\n",
        "            # í‰ê· ë³´ë‹¤ ë§ê±°ë‚˜ ê°™ìœ¼ë©´ sampling_strategyì— í¬í•¨í•˜ì§€ ì•ŠìŒ (ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
        "    elif strategy == \"minority\":\n",
        "        # ì†Œìˆ˜ í´ë˜ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¤ (ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ë¡œ)\n",
        "        # í•˜ì§€ë§Œ ì˜¤ë²„ìƒ˜í”Œë§ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ, ìµœì†Œë³´ë‹¤ ì ì€ í´ë˜ìŠ¤ë§Œ ìµœì†Œë¡œ ë§ì¶¤\n",
        "        sampling_strategy = {}\n",
        "        for label_id, count in before_counts.items():\n",
        "            if count < min_samples:\n",
        "                sampling_strategy[label_id] = min_samples\n",
        "    elif strategy == \"majority\":\n",
        "        # ë‹¤ìˆ˜ í´ë˜ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¤ (ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ë¡œ)\n",
        "        sampling_strategy = {label_id: max_samples for label_id in before_counts.index}\n",
        "    else:\n",
        "        # ì‚¬ìš©ì ì •ì˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°, í‰ê· ë³´ë‹¤ ì ì€ í´ë˜ìŠ¤ë§Œ í•„í„°ë§\n",
        "        sampling_strategy = {}\n",
        "        for label_id, target_count in strategy.items():\n",
        "            current_count = before_counts[label_id]\n",
        "            if target_count >= current_count:\n",
        "                # ì˜¤ë²„ìƒ˜í”Œë§ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ, í˜„ì¬ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì„ ë•Œë§Œ ì ìš©\n",
        "                sampling_strategy[label_id] = target_count\n",
        "            else:\n",
        "                print(f\"   âš ï¸ {ID2LABEL[label_id]} (ID {label_id}): {current_count}ê°œ â†’ {target_count}ê°œë¡œ ì¤„ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒ˜í”Œ ìˆ˜ ìœ ì§€.\")\n",
        "    \n",
        "    if not sampling_strategy:\n",
        "        print(\"\\n   âš ï¸ ìƒ˜í”Œë§í•  í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í´ë˜ìŠ¤ê°€ ì´ë¯¸ ì¶©ë¶„í•œ ìƒ˜í”Œì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
        "        return df\n",
        "    \n",
        "    print(f\"\\n   ğŸ“ ìƒ˜í”Œë§ ëŒ€ìƒ: {len(sampling_strategy)}ê°œ í´ë˜ìŠ¤\")\n",
        "    for label_id, target_count in sampling_strategy.items():\n",
        "        current_count = before_counts[label_id]\n",
        "        emotion = ID2LABEL[label_id]\n",
        "        print(f\"      {emotion:10s} (ID {label_id}): {current_count:6,}ê°œ â†’ {target_count:6,}ê°œ\")\n",
        "    \n",
        "    # Oversampling (ë¶€ì¡±í•œ í´ë˜ìŠ¤ ì¦ê°•)\n",
        "    oversampler = RandomOverSampler(\n",
        "        sampling_strategy=sampling_strategy,\n",
        "        random_state=RANDOM_SEED\n",
        "    )\n",
        "    \n",
        "    # í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  label_idë§Œ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œë§\n",
        "    X = df[['text']].values\n",
        "    y = df['label_id'].values\n",
        "    \n",
        "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "    \n",
        "    # ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±\n",
        "    df_balanced = pd.DataFrame({\n",
        "        'text': X_resampled.flatten(),\n",
        "        'label_id': y_resampled\n",
        "    })\n",
        "    \n",
        "    # emotion ì»¬ëŸ¼ ì¶”ê°€\n",
        "    df_balanced['emotion'] = df_balanced['label_id'].map(ID2LABEL)\n",
        "    \n",
        "    # ìƒ˜í”Œë§ í›„ ë¶„í¬\n",
        "    print(\"\\nğŸ“Š ìƒ˜í”Œë§ í›„ ë¶„í¬:\")\n",
        "    after_counts = df_balanced['label_id'].value_counts().sort_index()\n",
        "    for label_id, count in after_counts.items():\n",
        "        emotion = ID2LABEL[label_id]\n",
        "        print(f\"   {emotion:10s} (ID {label_id}): {count:6,}ê°œ\")\n",
        "    \n",
        "    print(f\"\\n   ì´ ìƒ˜í”Œ ìˆ˜: {len(df_balanced):,}ê°œ (ì´ì „: {len(df):,}ê°œ)\")\n",
        "    \n",
        "    return df_balanced\n",
        "\n",
        "\n",
        "# ë¶ˆê· í˜• í•´ì†Œ ì ìš©\n",
        "if USE_SAMPLING:\n",
        "    df = balance_dataset(df, strategy=SAMPLING_STRATEGY)\n",
        "else:\n",
        "    print(\"\\nâš ï¸ ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– 7. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_NAME}\")\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=ID2LABEL,\n",
        "    label2id=LABEL2ID\n",
        ")\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(f\"âœ… ëª¨ë¸ì„ {device}ë¡œ ì´ë™ ì™„ë£Œ\")\n",
        "\n",
        "print(f\"\\nğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ 8. í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    precision = precision_score(labels, predictions, average='weighted')\n",
        "    recall = recall_score(labels, predictions, average='weighted')\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "\n",
        "def print_classification_report(y_true, y_pred, labels=None):\n",
        "    \"\"\"ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶œë ¥\"\"\"\n",
        "    if labels is None:\n",
        "        labels = [ID2LABEL[i] for i in range(NUM_LABELS)]\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸\")\n",
        "    print(\"=\"*60)\n",
        "    print(classification_report(y_true, y_pred, target_names=labels, digits=4))\n",
        "    \n",
        "    # í˜¼ë™ í–‰ë ¬\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "    plt.ylabel('ì‹¤ì œ', fontsize=12)\n",
        "    plt.xlabel('ì˜ˆì¸¡', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”€ 9. K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "texts = df['text'].tolist()\n",
        "labels = df['label_id'].tolist()\n",
        "\n",
        "# K-Fold ë¶„í• \n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "fold_results = []\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "print(f\"ğŸš€ K-Fold êµì°¨ ê²€ì¦ ì‹œì‘ ({N_FOLDS} folds)\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels), 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ“ Fold {fold}/{N_FOLDS}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• \n",
        "    train_texts = [texts[i] for i in train_idx]\n",
        "    train_labels = [labels[i] for i in train_idx]\n",
        "    val_texts = [texts[i] for i in val_idx]\n",
        "    val_labels = [labels[i] for i in val_idx]\n",
        "    \n",
        "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í• :\")\n",
        "    print(f\"   í•™ìŠµ: {len(train_texts):,}ê°œ\")\n",
        "    print(f\"   ê²€ì¦: {len(val_texts):,}ê°œ\")\n",
        "    \n",
        "    # HuggingFace Datasetìœ¼ë¡œ ë³€í™˜\n",
        "    train_dataset = HFDataset.from_dict({\n",
        "        'text': train_texts,\n",
        "        'label': train_labels\n",
        "    })\n",
        "    \n",
        "    val_dataset = HFDataset.from_dict({\n",
        "        'text': val_texts,\n",
        "        'label': val_labels\n",
        "    })\n",
        "    \n",
        "    # í† í°í™”\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "    \n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "    \n",
        "    # ë¼ë²¨ ì„¤ì •\n",
        "    train_dataset = train_dataset.rename_column('label', 'labels')\n",
        "    val_dataset = val_dataset.rename_column('label', 'labels')\n",
        "    \n",
        "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "    val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "    \n",
        "    # ëª¨ë¸ ì¬ì´ˆê¸°í™” (ê° foldë§ˆë‹¤ ìƒˆë¡œ í•™ìŠµ)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=NUM_LABELS,\n",
        "        id2label=ID2LABEL,\n",
        "        label2id=LABEL2ID\n",
        "    )\n",
        "    \n",
        "    # í•™ìŠµ ì¸ì ì„¤ì •\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'./checkpoints/fold_{fold}',\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        warmup_steps=WARMUP_STEPS,\n",
        "        logging_dir=f'./logs/fold_{fold}',\n",
        "        logging_steps=100,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1',\n",
        "        greater_is_better=True,\n",
        "        save_total_limit=2,\n",
        "        seed=RANDOM_SEED,\n",
        "        fp16=torch.cuda.is_available(),  # GPU ì‚¬ìš© ì‹œ í˜¼í•© ì •ë°€ë„\n",
        "        report_to='none',  # wandb ë“± ì‚¬ìš© ì‹œ 'wandb'ë¡œ ë³€ê²½\n",
        "    )\n",
        "    \n",
        "    # Trainer ìƒì„±\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    \n",
        "    # í•™ìŠµ\n",
        "    print(f\"\\nğŸ“ í•™ìŠµ ì‹œì‘...\")\n",
        "    train_result = trainer.train()\n",
        "    \n",
        "    # í‰ê°€\n",
        "    print(f\"\\nğŸ“Š í‰ê°€ ì¤‘...\")\n",
        "    eval_result = trainer.evaluate()\n",
        "    \n",
        "    # ì˜ˆì¸¡\n",
        "    predictions = trainer.predict(val_dataset)\n",
        "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "    \n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    fold_results.append({\n",
        "        'fold': fold,\n",
        "        'accuracy': eval_result['eval_accuracy'],\n",
        "        'f1': eval_result['eval_f1'],\n",
        "        'precision': eval_result['eval_precision'],\n",
        "        'recall': eval_result['eval_recall']\n",
        "    })\n",
        "    \n",
        "    all_predictions.extend(y_pred.tolist())\n",
        "    all_labels.extend(val_labels)\n",
        "    \n",
        "    print(f\"\\nâœ… Fold {fold} ì™„ë£Œ!\")\n",
        "    print(f\"   Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
        "    print(f\"   F1 Score: {eval_result['eval_f1']:.4f}\")\n",
        "    print(f\"   Precision: {eval_result['eval_precision']:.4f}\")\n",
        "    print(f\"   Recall: {eval_result['eval_recall']:.4f}\")\n",
        "    \n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del model, trainer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ğŸ‰ K-Fold êµì°¨ ê²€ì¦ ì™„ë£Œ!\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 10. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Foldë³„ ê²°ê³¼ ìš”ì•½\n",
        "results_df = pd.DataFrame(fold_results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š K-Fold ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ˆ í‰ê·  ì„±ëŠ¥\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy: {results_df['accuracy'].mean():.4f} (Â±{results_df['accuracy'].std():.4f})\")\n",
        "print(f\"F1 Score:  {results_df['f1'].mean():.4f} (Â±{results_df['f1'].std():.4f})\")\n",
        "print(f\"Precision: {results_df['precision'].mean():.4f} (Â±{results_df['precision'].std():.4f})\")\n",
        "print(f\"Recall:    {results_df['recall'].mean():.4f} (Â±{results_df['recall'].std():.4f})\")\n",
        "\n",
        "# ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "metrics = ['accuracy', 'f1', 'precision', 'recall']\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    ax.bar(range(1, N_FOLDS + 1), results_df[metric], color='#4ECDC4', alpha=0.7)\n",
        "    ax.axhline(y=results_df[metric].mean(), color='r', linestyle='--', label='í‰ê· ')\n",
        "    ax.set_title(f'{metric.upper()}', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Fold', fontsize=12)\n",
        "    ax.set_ylabel('Score', fontsize=12)\n",
        "    ax.set_xticks(range(1, N_FOLDS + 1))\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ (ëª¨ë“  Fold í†µí•©)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "overall_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
        "\n",
        "print(f\"\\nì „ì²´ Accuracy: {overall_accuracy:.4f}\")\n",
        "print(f\"ì „ì²´ F1 Score: {overall_f1:.4f}\")\n",
        "\n",
        "# ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
        "print_classification_report(all_labels, all_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¾ 11. ìµœì¢… ëª¨ë¸ ì €ì¥ (ì„ íƒì‚¬í•­)\n",
        "\n",
        "ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ Foldì˜ ëª¨ë¸ì„ ì €ì¥í•˜ê±°ë‚˜, ëª¨ë“  Fold ëª¨ë¸ì˜ ì•™ìƒë¸”ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ Fold ì°¾ê¸°\n",
        "best_fold = results_df.loc[results_df['f1'].idxmax(), 'fold']\n",
        "print(f\"ğŸ† ìµœê³  ì„±ëŠ¥ Fold: {int(best_fold)} (F1: {results_df.loc[results_df['f1'].idxmax(), 'f1']:.4f})\")\n",
        "\n",
        "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ë° ì €ì¥\n",
        "# ê° foldì˜ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì•„ì„œ ì €ì¥\n",
        "import glob\n",
        "\n",
        "best_fold_dir = f'./checkpoints/fold_{int(best_fold)}'\n",
        "checkpoint_dirs = sorted(glob.glob(f'{best_fold_dir}/checkpoint-*'), \n",
        "                         key=lambda x: int(x.split('-')[-1]))\n",
        "\n",
        "if checkpoint_dirs:\n",
        "    best_model_path = checkpoint_dirs[-1]  # ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸\n",
        "    print(f\"\\nğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ ì¤‘...\")\n",
        "    print(f\"   ëª¨ë¸ ê²½ë¡œ: {best_model_path}\")\n",
        "    \n",
        "    # ëª¨ë¸ ë¡œë“œ\n",
        "    final_model = AutoModelForSequenceClassification.from_pretrained(best_model_path)\n",
        "    final_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    \n",
        "    # ì €ì¥\n",
        "    save_path = './best_emotion_model'\n",
        "    final_model.save_pretrained(save_path)\n",
        "    final_tokenizer.save_pretrained(save_path)\n",
        "    \n",
        "    print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
        "    print(f\"\\nğŸ“ ì‚¬ìš© ë°©ë²•:\")\n",
        "    print(f\"   from transformers import AutoTokenizer, AutoModelForSequenceClassification\")\n",
        "    print(f\"   tokenizer = AutoTokenizer.from_pretrained('{save_path}')\")\n",
        "    print(f\"   model = AutoModelForSequenceClassification.from_pretrained('{save_path}')\")\n",
        "else:\n",
        "    print(f\"âš ï¸ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {best_fold_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª 12. í…ŒìŠ¤íŠ¸ ì˜ˆì œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì €ì¥ëœ ëª¨ë¸ì´ ìˆëŠ” ê²½ìš° í…ŒìŠ¤íŠ¸\n",
        "if os.path.exists('./best_emotion_model'):\n",
        "    # ëª¨ë¸ ë¡œë“œ\n",
        "    test_model = AutoModelForSequenceClassification.from_pretrained('./best_emotion_model')\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained('./best_emotion_model')\n",
        "    test_model.to(device)\n",
        "    test_model.eval()\n",
        "    \n",
        "    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤\n",
        "    test_sentences = [\n",
        "        \"ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„! íšŒì‚¬ì—ì„œ í”„ë¡œì íŠ¸ê°€ ì„±ê³µí–ˆì–´.\",\n",
        "        \"ë©´ì ‘ì—ì„œ ë–¨ì–´ì ¸ì„œ ë„ˆë¬´ ìŠ¬í”„ê³  í˜ë“¤ì–´.\",\n",
        "        \"ë‚´ì¼ ë©´ì ‘ì¸ë° ë„ˆë¬´ ë¶ˆì•ˆí•˜ê³  ê±±ì •ë¼.\",\n",
        "        \"ìƒì‚¬ê°€ ìê¾¸ ì•¼ê·¼ì„ ì‹œì¼œì„œ ì •ë§ í™”ê°€ ë‚˜!\",\n",
        "        \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”. í‰ë²”í•œ í•˜ë£¨ì…ë‹ˆë‹¤.\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ§ª ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for sentence in test_sentences:\n",
        "        # í† í°í™”\n",
        "        inputs = test_tokenizer(\n",
        "            sentence,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "        \n",
        "        # ì˜ˆì¸¡\n",
        "        with torch.no_grad():\n",
        "            outputs = test_model(**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            predicted_id = predictions.argmax().item()\n",
        "            confidence = predictions[0][predicted_id].item()\n",
        "        \n",
        "        predicted_emotion = ID2LABEL[predicted_id]\n",
        "        \n",
        "        print(f\"\\në¬¸ì¥: {sentence}\")\n",
        "        print(f\"ì˜ˆì¸¡: {predicted_emotion} (ì‹ ë¢°ë„: {confidence:.4f})\")\n",
        "        print(f\"   {dict(zip([ID2LABEL[i] for i in range(NUM_LABELS)], [f'{p:.4f}' for p in predictions[0].cpu().numpy()]))}\")\n",
        "else:\n",
        "    print(\"âš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ 13. ìš”ì•½ ë° ê°œì„  ì‚¬í•­\n",
        "\n",
        "### ì„±ëŠ¥ ê°œì„  íŒ:\n",
        "\n",
        "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**:\n",
        "   - Learning Rate: 1e-5 ~ 5e-5 ë²”ìœ„ì—ì„œ ì‹¤í—˜\n",
        "   - Batch Size: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì • (16, 32, 64)\n",
        "   - Max Length: 128 ë˜ëŠ” 256ìœ¼ë¡œ ì‹¤í—˜\n",
        "\n",
        "2. **ë°ì´í„° ì¦ê°•**:\n",
        "   - Back-translation (í•œêµ­ì–´ â†’ ì˜ì–´ â†’ í•œêµ­ì–´)\n",
        "   - ë™ì˜ì–´ êµì²´\n",
        "   - ë¬¸ì¥ ìˆœì„œ ë³€ê²½\n",
        "\n",
        "3. **ì•™ìƒë¸”**:\n",
        "   - ì—¬ëŸ¬ ëª¨ë¸ (KoBERT, KoELECTRA, KC-BERT) ì¡°í•©\n",
        "   - ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë˜ëŠ” í‰ê·  í™•ë¥  ì‚¬ìš©\n",
        "\n",
        "4. **ê³ ê¸‰ ê¸°ë²•**:\n",
        "   - Focal Loss (ë¶ˆê· í˜• ë°ì´í„°ìš©)\n",
        "   - Class Weight ì¡°ì •\n",
        "   - ë” í° ëª¨ë¸ ì‚¬ìš© (KoBERT-large ë“±)\n",
        "\n",
        "---\n",
        "\n",
        "**ì‘ì„±ì¼**: 2025ë…„  \n",
        "**ëª¨ë¸**: KoBERT (monologg/kobert)  \n",
        "**ëª©ì **: í•œêµ­ì–´ ê°ì • ë¶„ì„ ìµœì í™”\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
