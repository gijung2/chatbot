# ğŸš€ ML Serving - ê°ì • ë¶„ì„ API

KLUE-BERT ê¸°ë°˜ í•œêµ­ì–´ ê°ì • ë¶„ì„ ë° ì•„ë°”íƒ€ ìƒì„± API ì„œë²„

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
cd ml-serving
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘ (í•„ìš”ì‹œ)
```

### 3. ì„œë²„ ì‹¤í–‰
```bash
# ê°œë°œ ëª¨ë“œ (ìë™ ì¬ì‹œì‘)
python -m app.main

# ë˜ëŠ” uvicorn ì§ì ‘ ì‹¤í–‰
uvicorn app.main:app --reload --port 8000
```

### 4. API ë¬¸ì„œ í™•ì¸
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### ê°ì • ë¶„ì„
```bash
POST /api/v1/analyze
{
  "text": "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!"
}
```

### ì•„ë°”íƒ€ ìƒì„±
```bash
POST /api/v1/generate-avatar
{
  "text": "ì˜¤ëŠ˜ ë„ˆë¬´ í–‰ë³µí•´ìš”!",
  "style": "gradient"
}
```

### í—¬ìŠ¤ì²´í¬
```bash
GET /api/v1/health
```

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ml-serving/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI ì•±
â”‚   â”œâ”€â”€ config.py            # ì„¤ì •
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â””â”€â”€ endpoints/   # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ models/              # ML ëª¨ë¸
â”‚   â”œâ”€â”€ schemas/             # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ services/            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

## ğŸ”§ ì„¤ì •

`.env` íŒŒì¼ì—ì„œ ë‹¤ìŒ í•­ëª©ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `MODEL_PATH`: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
- `DEVICE`: ë””ë°”ì´ìŠ¤ (auto, cuda, cpu)
- `PORT`: ì„œë²„ í¬íŠ¸
- `DEBUG`: ë””ë²„ê·¸ ëª¨ë“œ

## ğŸ“Š ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "text": "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!",
  "emotion": "joy",
  "emotion_kr": "ê¸°ì¨",
  "confidence": 0.92,
  "probabilities": {
    "joy": 0.92,
    "sad": 0.02,
    "anxiety": 0.03,
    "anger": 0.01,
    "neutral": 0.02
  },
  "risk_level": "low",
  "risk_message": "ğŸ’š ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.",
  "emotion_message": "ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ëŠê»´ì ¸ìš”!",
  "method": "klue-bert-kfold",
  "inference_time_ms": 45.2
}
```

## ğŸ³ Docker ì‹¤í–‰

```bash
docker build -t ml-serving .
docker run -p 8000:8000 ml-serving
```

## ğŸ“ ê°œë°œ

### í…ŒìŠ¤íŠ¸
```bash
pytest tests/
```

### ì½”ë“œ í’ˆì§ˆ
```bash
black app/
flake8 app/
mypy app/
```
