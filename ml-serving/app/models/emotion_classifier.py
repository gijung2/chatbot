"""
Emotion Classification Model
"""
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from typing import Dict, Tuple
import time

from app.config import settings

class EmotionClassifier(nn.Module):
    """KLUE-BERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self, bert_model, num_labels: int = 5):
        super().__init__()
        self.bert = bert_model
        self.dropout = nn.Dropout(settings.DROPOUT_RATE)
        self.classifier = nn.Linear(bert_model.config.hidden_size, num_labels)
        
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        return logits

class EmotionModelService:
    """ê°ì • ë¶„ì„ ëª¨ë¸ ì„œë¹„ìŠ¤"""
    
    EMOTION_LABELS = ['joy', 'sad', 'anxiety', 'anger', 'neutral']
    EMOTION_KR = {
        'joy': 'ê¸°ì¨',
        'sad': 'ìŠ¬í””',
        'anxiety': 'ë¶ˆì•ˆ',
        'anger': 'ë¶„ë…¸',
        'neutral': 'ì¤‘ë¦½'
    }
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.device = None
        self._is_loaded = False
        
    def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            if settings.DEVICE == "auto":
                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            else:
                self.device = torch.device(settings.DEVICE)
            
            print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(settings.MODEL_NAME)
            print("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")
            
            # BERT ëª¨ë¸ ë¡œë“œ
            bert_model = AutoModel.from_pretrained(settings.MODEL_NAME)
            self.model = EmotionClassifier(bert_model, num_labels=settings.NUM_LABELS)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            import os
            if not os.path.exists(settings.MODEL_PATH):
                print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {settings.MODEL_PATH}")
                return False
            
            checkpoint = torch.load(settings.MODEL_PATH, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {settings.MODEL_PATH}")
            if 'val_acc_history' in checkpoint and len(checkpoint['val_acc_history']) > 0:
                acc = checkpoint['val_acc_history'][0]
                print(f"ğŸ“Š ê²€ì¦ ì •í™•ë„: {acc:.2%}")
            
            self._is_loaded = True
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._is_loaded = False
            return False
    
    def predict(self, text: str) -> Tuple[Dict, float]:
        """
        ê°ì • ì˜ˆì¸¡
        
        Returns:
            (result_dict, inference_time_ms)
        """
        if not self._is_loaded:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        start_time = time.time()
        
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            text,
            max_length=settings.MAX_LENGTH,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        input_ids = encoding['input_ids'].to(self.device)
        attention_mask = encoding['attention_mask'].to(self.device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            logits = self.model(input_ids, attention_mask)
            probabilities = torch.nn.functional.softmax(logits, dim=1)
            confidence, predicted_class = torch.max(probabilities, dim=1)
        
        emotion = self.EMOTION_LABELS[predicted_class.item()]
        
        # í™•ë¥  ë”•ì…”ë„ˆë¦¬
        probs_dict = {
            self.EMOTION_LABELS[i]: float(probabilities[0][i])
            for i in range(len(self.EMOTION_LABELS))
        }
        
        inference_time_ms = (time.time() - start_time) * 1000
        
        result = {
            'emotion': emotion,
            'emotion_kr': self.EMOTION_KR[emotion],
            'confidence': float(confidence.item()),
            'probabilities': probs_dict,
            'method': 'klue-bert-kfold'
        }
        
        return result, inference_time_ms
    
    @property
    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ì—¬ë¶€"""
        return self._is_loaded

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
emotion_model_service = EmotionModelService()
