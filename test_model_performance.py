"""
ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python test_model_performance.py

ì˜µì…˜:
    --model_path: ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: checkpoints_kfold)
    --detailed: ìƒì„¸ ê²°ê³¼ ì¶œë ¥
"""

import sys
import argparse
from pathlib import Path

# FastAPI ì•± ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent / 'fastapi_app'))

from fastapi_app.models.emotion_model_hf import EmotionClassifierHF


# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (ë‹¤ì–‘í•œ ê°ì • í‘œí˜„)
TEST_CASES = [
    # Joy (ê¸°ì¨)
    ("ì˜¤ëŠ˜ ì •ë§ í–‰ë³µí•´ìš”!", "joy"),
    ("ì™„ì „ ê¸°ë¶„ ì¢‹ì•„!", "joy"),
    ("ë„ˆë¬´ ê¸°ë»ì„œ ë‚ ì•„ê°ˆ ê²ƒ ê°™ì•„ìš”", "joy"),
    ("ì™€! ëŒ€ë°•! ì •ë§ ì¢‹ì•„ìš”!", "joy"),
    ("í–‰ë³µí•œ í•˜ë£¨ì˜€ì–´ìš”", "joy"),
    
    # Sad (ìŠ¬í””)
    ("ë„ˆë¬´ ìŠ¬í¼ì„œ ëˆˆë¬¼ì´ ë‚˜ìš”", "sad"),
    ("ìš°ìš¸í•´ ì£½ê² ì–´", "sad"),
    ("ë§ˆìŒì´ ì•„íŒŒìš”", "sad"),
    ("ìŠ¬í”ˆ ì¼ì´ ìˆì—ˆì–´ìš”", "sad"),
    ("ê¸°ë¶„ì´ ë„ˆë¬´ ë‹¤ìš´ë¼ìš”", "sad"),
    
    # Anxiety (ë¶ˆì•ˆ)
    ("ì‹œí—˜ì´ ê±±ì •ë¼ìš”", "anxiety"),
    ("ë–¨ë ¤ìš” ë„ˆë¬´", "anxiety"),
    ("ë¶ˆì•ˆí•´ì„œ ì ì„ ëª» ììš”", "anxiety"),
    ("ë¬´ì„œì›Œìš”", "anxiety"),
    ("ê±±ì •ì´ ë§ì•„ìš”", "anxiety"),
    
    # Anger (ë¶„ë…¸)
    ("í™”ê°€ ë‚˜ì„œ ë¯¸ì¹  ê²ƒ ê°™ì•„ìš”", "anger"),
    ("ì§œì¦ë‚˜!", "anger"),
    ("ì •ë§ ì—´ë°›ì•„ìš”", "anger"),
    ("ë„ˆë¬´ í™”ë‚˜ì„œ ë§ë„ ëª»í•˜ê² ì–´ìš”", "anger"),
    ("ì§„ì§œ ë¹¡ì³ìš”", "anger"),
    
    # Neutral (ì¤‘ë¦½)
    ("ê·¸ëƒ¥ ê·¸ë˜ìš”", "neutral"),
    ("ë³„ë¡œ íŠ¹ë³„í•œ ì¼ ì—†ì–´ìš”", "neutral"),
    ("í‰ë²”í•œ í•˜ë£¨ì˜ˆìš”", "neutral"),
    ("ê·¸ì € ê·¸ë˜ìš”", "neutral"),
    ("ë­ ê·¸ëƒ¥ ë³´í†µì´ì—ìš”", "neutral"),
    
    # Edge Cases (ê²½ê³„ ì¼€ì´ìŠ¤)
    ("ê¸°ì˜ë©´ì„œë„ ìŠ¬í¼ìš”", "neutral"),  # í˜¼í•© ê°ì •
    ("í™”ë‚˜ëŠ”ë° ê±±ì •ë„ ë¼ìš”", "anxiety"),  # ë³µí•© ê°ì •
    ("", "neutral"),  # ë¹ˆ ë¬¸ìì—´
    ("ã…‹ã…‹ã…‹ã…‹", "joy"),  # ì´ëª¨í‹°ì½˜
    ("ã… ã… ã… ã… ", "sad"),  # ì´ëª¨í‹°ì½˜
]


def test_model(model_path: str = None, detailed: bool = False):
    """ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 80)
    print("ğŸ§ª ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        print(f"\nğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = EmotionClassifierHF(model_path=model_path)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path or 'ê¸°ë³¸ ê²½ë¡œ'}\n")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    if detailed:
        info = model.get_model_info()
        print("ğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"   - ëª¨ë¸ íƒ€ì…: {info['model_type']}")
        print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {info['total_parameters']:,}")
        print(f"   - Device: {info['device']}")
        print(f"   - ê°ì • í´ë˜ìŠ¤: {', '.join(info['emotion_labels'])}")
        print()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=" * 80)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰")
    print("=" * 80)
    
    results = {
        'total': 0,
        'correct': 0,
        'by_emotion': {emotion: {'total': 0, 'correct': 0} for emotion in model.emotion_labels}
    }
    
    confidences = []
    
    for text, expected in TEST_CASES:
        if not text:  # ë¹ˆ ë¬¸ìì—´ ìŠ¤í‚µ
            continue
            
        result = model.predict_emotion(text)
        predicted = result['emotion']
        confidence = result['confidence']
        
        is_correct = predicted == expected
        results['total'] += 1
        results['by_emotion'][expected]['total'] += 1
        
        if is_correct:
            results['correct'] += 1
            results['by_emotion'][expected]['correct'] += 1
        
        confidences.append(confidence)
        
        # ê²°ê³¼ ì¶œë ¥
        status = "âœ…" if is_correct else "âŒ"
        print(f"\n{status} \"{text}\"")
        print(f"   ì˜ˆì¸¡: {predicted} ({confidence:.2%} ì‹ ë¢°ë„)")
        
        if not is_correct:
            print(f"   ì •ë‹µ: {expected}")
        
        if detailed:
            print(f"   í™•ë¥  ë¶„í¬:")
            for emotion, prob in sorted(result['probabilities'].items(), key=lambda x: -x[1]):
                print(f"      - {emotion}: {prob:.2%}")
    
    # ì¢…í•© ê²°ê³¼
    print("\n" + "=" * 80)
    print("ğŸ“Š ì¢…í•© ê²°ê³¼")
    print("=" * 80)
    
    overall_accuracy = results['correct'] / results['total'] * 100
    avg_confidence = sum(confidences) / len(confidences)
    
    print(f"\nğŸ¯ ì „ì²´ ì •í™•ë„: {overall_accuracy:.1f}% ({results['correct']}/{results['total']})")
    print(f"ğŸ“ˆ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2%}")
    
    # ê°ì •ë³„ ì •í™•ë„
    print(f"\nğŸ“‹ ê°ì •ë³„ ì •í™•ë„:")
    for emotion in model.emotion_labels:
        total = results['by_emotion'][emotion]['total']
        correct = results['by_emotion'][emotion]['correct']
        
        if total > 0:
            accuracy = correct / total * 100
            print(f"   - {emotion:8s}: {accuracy:5.1f}% ({correct}/{total})")
        else:
            print(f"   - {emotion:8s}: N/A (í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì—†ìŒ)")
    
    # ì„±ëŠ¥ í‰ê°€
    print("\n" + "=" * 80)
    print("ğŸ’¡ ì„±ëŠ¥ í‰ê°€")
    print("=" * 80)
    
    if overall_accuracy >= 95:
        grade = "ğŸ† ìš°ìˆ˜ (Excellent)"
        message = "ëª¨ë¸ì´ ë§¤ìš° ì˜ ì‘ë™í•©ë‹ˆë‹¤!"
    elif overall_accuracy >= 90:
        grade = "ğŸ¥‡ ì¢‹ìŒ (Good)"
        message = "ëª¨ë¸ì´ ì˜ ì‘ë™í•©ë‹ˆë‹¤."
    elif overall_accuracy >= 80:
        grade = "ğŸ¥ˆ ë³´í†µ (Fair)"
        message = "ì¶”ê°€ í•™ìŠµì´ ê¶Œì¥ë©ë‹ˆë‹¤."
    else:
        grade = "ğŸ¥‰ ê°œì„  í•„ìš” (Needs Improvement)"
        message = "ëª¨ë¸ ì¬í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    print(f"\në“±ê¸‰: {grade}")
    print(f"í‰ê°€: {message}")
    
    if avg_confidence < 0.7:
        print(f"\nâš ï¸ í‰ê·  ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({avg_confidence:.2%})")
        print("   â†’ KOTE ë°ì´í„°ë¡œ ì¬í•™ìŠµ ê¶Œì¥")
    
    # ê°œì„  ì œì•ˆ
    print("\nğŸ“Œ ê°œì„  ì œì•ˆ:")
    
    weak_emotions = []
    for emotion in model.emotion_labels:
        total = results['by_emotion'][emotion]['total']
        correct = results['by_emotion'][emotion]['correct']
        if total > 0 and correct / total < 0.8:
            weak_emotions.append(emotion)
    
    if weak_emotions:
        print(f"   - ì•½í•œ í´ë˜ìŠ¤: {', '.join(weak_emotions)}")
        print(f"   â†’ í•´ë‹¹ í´ë˜ìŠ¤ ë°ì´í„° ì¦ê°• ê¶Œì¥")
    
    if overall_accuracy < 95:
        print(f"   - KOTE ë°ì´í„°ë¡œ ì¬í•™ìŠµ (176K samples)")
        print(f"   - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (epochs=15, lr=2e-5)")
        print(f"   - Label smoothing ì ìš©")
    
    if avg_confidence < 0.8:
        print(f"   - Temperature scaling ì ìš©")
        print(f"   - Threshold ì¡°ì •")
    
    print("\n" + "=" * 80)
    print(f"ìƒì„¸ ê°€ì´ë“œ: PERFORMANCE_IMPROVEMENT_GUIDE.md")
    print("=" * 80)
    print()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    parser.add_argument(
        '--model_path',
        type=str,
        default=None,
        help='ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: checkpoints_kfold)'
    )
    parser.add_argument(
        '--detailed',
        action='store_true',
        help='ìƒì„¸ ê²°ê³¼ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    test_model(model_path=args.model_path, detailed=args.detailed)
