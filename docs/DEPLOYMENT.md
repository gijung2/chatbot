# ğŸš€ ëª¨ë¸ ë°°í¬ ê°€ì´ë“œ

## ğŸ“¦ í•™ìŠµëœ ëª¨ë¸ ì •ë³´

### K-Fold Cross Validation ê²°ê³¼ (2024-10-28)

**í•™ìŠµ ì„¤ì •:**
- ë°ì´í„°ì…‹: ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜ (41,387 samples)
- ëª¨ë¸: klue/bert-base
- K-Fold: 2-fold (í…ŒìŠ¤íŠ¸)
- Epoch: 1 (ë¹ ë¥¸ ê²€ì¦)
- Batch Size: 16
- Learning Rate: 2e-5

**Fold 1 ì„±ëŠ¥:**
- Validation Accuracy: **59.74%**
- Validation F1 Score: **59.19%** (weighted)
- Validation Loss: **0.9398**

**í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:**
| ê°ì • | Precision | Recall | F1-Score |
|------|-----------|--------|----------|
| joy | 0.478 | 0.734 | 0.579 |
| sad | 0.519 | 0.556 | 0.537 |
| anxiety | 0.632 | 0.715 | **0.671** â­ |
| anger | 0.700 | 0.446 | 0.545 |
| neutral | 0.616 | 0.301 | 0.405 |

**ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜:**
```
checkpoints_kfold/fold1_model_20251028_113127.pt
```

---

## ğŸ”§ ëª¨ë¸ ë¡œë“œ ë° ì‚¬ìš© ë°©ë²•

### 1. ëª¨ë¸ ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

```python
import torch
from transformers import AutoTokenizer
from training.model import create_model

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')

# ëª¨ë¸ ìƒì„±
model = create_model(
    model_name='klue/bert-base',
    num_labels=5,
    dropout_rate=0.3,
    freeze_bert=False,
    device=device
)

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
checkpoint = torch.load('checkpoints_kfold/fold1_model_20251028_113127.pt', 
                       map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
print(f"ğŸ“Š ëª¨ë¸ ì„¤ì •: {checkpoint['model_config']}")
```

### 2. ê°ì • ì˜ˆì¸¡ í•¨ìˆ˜

```python
def predict_emotion(text: str, model, tokenizer, device):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡
    
    Args:
        text: ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸
        model: í•™ìŠµëœ ëª¨ë¸
        tokenizer: í† í¬ë‚˜ì´ì €
        device: ë””ë°”ì´ìŠ¤
    
    Returns:
        predicted_label: ì˜ˆì¸¡ëœ ê°ì • (0-4)
        probabilities: ê° í´ë˜ìŠ¤ë³„ í™•ë¥ 
        emotion_name: ê°ì • ì´ë¦„
    """
    # í…ìŠ¤íŠ¸ í† í°í™”
    encoding = tokenizer(
        text,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs['logits']
        probabilities = torch.softmax(logits, dim=-1)
        predicted_label = torch.argmax(probabilities, dim=-1).item()
    
    # ê°ì • ë§¤í•‘
    emotion_map = {
        0: 'joy',      # ê¸°ì¨
        1: 'sad',      # ìŠ¬í””
        2: 'anxiety',  # ë¶ˆì•ˆ
        3: 'anger',    # ë¶„ë…¸
        4: 'neutral'   # ì¤‘ë¦½
    }
    
    return predicted_label, probabilities[0].cpu().numpy(), emotion_map[predicted_label]

# ì‚¬ìš© ì˜ˆì‹œ
text = "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„!"
label, probs, emotion = predict_emotion(text, model, tokenizer, device)
print(f"í…ìŠ¤íŠ¸: {text}")
print(f"ì˜ˆì¸¡ ê°ì •: {emotion} (ë¼ë²¨: {label})")
print(f"í™•ë¥ : {probs}")
```

---

## ğŸŒ API ì„œë²„ì— í†µí•©

### FastAPI í†µí•© ì˜ˆì‹œ

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer
from training.model import create_model

app = FastAPI(title="ê°ì • ë¶„ë¥˜ API")

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')

model = create_model(
    model_name='klue/bert-base',
    num_labels=5,
    device=device
)

checkpoint = torch.load('checkpoints_kfold/fold1_model_20251028_113127.pt', 
                       map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

class EmotionRequest(BaseModel):
    text: str

class EmotionResponse(BaseModel):
    text: str
    emotion: str
    label: int
    probabilities: dict

@app.post("/predict", response_model=EmotionResponse)
async def predict_emotion_api(request: EmotionRequest):
    """ê°ì • ì˜ˆì¸¡ API"""
    label, probs, emotion = predict_emotion(
        request.text, model, tokenizer, device
    )
    
    return EmotionResponse(
        text=request.text,
        emotion=emotion,
        label=label,
        probabilities={
            'joy': float(probs[0]),
            'sad': float(probs[1]),
            'anxiety': float(probs[2]),
            'anger': float(probs[3]),
            'neutral': float(probs[4])
        }
    )

# ì‹¤í–‰: uvicorn api:app --reload
```

---

## ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ

### 1. **ë” ë§ì€ Epoch í•™ìŠµ**
í˜„ì¬ 1 epochë§Œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. ê¶Œì¥: 10-20 epochs

```powershell
python training\main_kfold.py --k_folds 5 --epochs 10 --batch_size 16
```

### 2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
- Learning Rate: 1e-5 ~ 5e-5 ì‹¤í—˜
- Batch Size: 32 (GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ ì‹œ)
- Dropout: 0.1 ~ 0.5 ë²”ìœ„ í…ŒìŠ¤íŠ¸

### 3. **ë°ì´í„° ì¦ê°•**
- Back-translation
- Synonym replacement
- Random deletion/insertion

### 4. **ì•™ìƒë¸”**
5-fold ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· ë‚´ì–´ ì‚¬ìš©

---

## ğŸ”’ ëª¨ë¸ íŒŒì¼ ê´€ë¦¬

### .gitignore ì„¤ì • (ì´ë¯¸ ì ìš©ë¨)
```
checkpoints/
checkpoints_kfold/
*.pt
*.pth
```

### ëª¨ë¸ íŒŒì¼ í¬ê¸°
- `fold1_model_20251028_113127.pt`: ~420MB

### ëŒ€ìš©ëŸ‰ íŒŒì¼ ê´€ë¦¬ ì˜µì…˜

**Option 1: Git LFS (ì¶”ì²œ)**
```bash
git lfs install
git lfs track "*.pt"
git add .gitattributes
git add checkpoints_kfold/*.pt
git commit -m "Add trained models with LFS"
```

**Option 2: ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€**
- Google Drive / Dropbox
- AWS S3 / Azure Blob Storage
- Hugging Face Model Hub

**Option 3: READMEì— ë‹¤ìš´ë¡œë“œ ë§í¬**
ëª¨ë¸ íŒŒì¼ì„ ë³„ë„ë¡œ ê³µìœ í•˜ê³  READMEì— ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ

---

## ğŸ“ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] ëª¨ë¸ í•™ìŠµ ì™„ë£Œ
- [x] ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
- [x] .gitignore ì„¤ì •
- [x] ë°°í¬ ê°€ì´ë“œ ë¬¸ì„œí™”
- [ ] API ì„œë²„ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **ì „ì²´ K-Fold í•™ìŠµ (ê¶Œì¥)**
   ```powershell
   python training\main_kfold.py --k_folds 5 --epochs 10
   ```

2. **API ì„œë²„ì— í†µí•©**
   - `fastapi_app/models/emotion_model.py` ì—…ë°ì´íŠ¸
   - ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •

3. **í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™**
   - ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ UIì— í‘œì‹œ
   - ì‹¤ì‹œê°„ ì•„ë°”íƒ€ í‘œì • ë³€í™”

4. **ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**
   - ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì 
   - ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§

---

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”.

**ì—…ë°ì´íŠ¸ ë‚ ì§œ:** 2024-10-28  
**ë²„ì „:** v1.0.0 (Initial K-Fold Test)
