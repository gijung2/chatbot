"""
í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ë° ì‚¬ìš© ìœ í‹¸ë¦¬í‹°

ì‚¬ìš©ë²•:
    python training/load_model.py --model_path checkpoints_kfold/fold1_model_20251028_113127.pt
"""
import argparse
import torch
from transformers import AutoTokenizer
from model import create_model
import numpy as np


def load_trained_model(model_path: str, device: str = 'cpu'):
    """
    í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        device: 'cuda' ë˜ëŠ” 'cpu'
    
    Returns:
        model: ë¡œë“œëœ ëª¨ë¸
        tokenizer: í† í¬ë‚˜ì´ì €
        config: ëª¨ë¸ ì„¤ì • ì •ë³´
    """
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {model_path}")
    checkpoint = torch.load(model_path, map_location=device)
    
    # ëª¨ë¸ ì„¤ì • í™•ì¸
    model_config = checkpoint.get('model_config', {})
    print(f"\nğŸ“Š ëª¨ë¸ ì„¤ì •:")
    for key, value in model_config.items():
        print(f"   - {key}: {value}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    model_name = model_config.get('model_name', 'klue/bert-base')
    print(f"\nğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë“œ: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    # ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
    model = create_model(
        model_name=model_name,
        num_labels=model_config.get('num_labels', 5),
        dropout_rate=0.3,
        freeze_bert=False,
        device=device
    )
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")
    
    # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ìˆëŠ” ê²½ìš°)
    if 'val_acc_history' in checkpoint:
        print(f"\nğŸ“ˆ í•™ìŠµ íˆìŠ¤í† ë¦¬:")
        print(f"   - Best Val Accuracy: {max(checkpoint['val_acc_history']):.4f}")
        print(f"   - Best Val F1: {max(checkpoint['val_f1_history']):.4f}")
        print(f"   - Final Val Loss: {checkpoint['val_loss_history'][-1]:.4f}")
    
    return model, tokenizer, model_config


def predict_emotion(text: str, model, tokenizer, device, max_length: int = 128):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡
    
    Args:
        text: ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸
        model: í•™ìŠµëœ ëª¨ë¸
        tokenizer: í† í¬ë‚˜ì´ì €
        device: ë””ë°”ì´ìŠ¤
        max_length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
    
    Returns:
        predicted_label: ì˜ˆì¸¡ëœ ê°ì • ë¼ë²¨ (0-4)
        probabilities: ê° í´ë˜ìŠ¤ë³„ í™•ë¥ 
        emotion_name: ê°ì • ì´ë¦„
        korean_name: í•œê¸€ ê°ì • ì´ë¦„
    """
    # ê°ì • ë§¤í•‘
    emotion_map = {
        0: ('joy', 'ê¸°ì¨'),
        1: ('sad', 'ìŠ¬í””'),
        2: ('anxiety', 'ë¶ˆì•ˆ'),
        3: ('anger', 'ë¶„ë…¸'),
        4: ('neutral', 'ì¤‘ë¦½')
    }
    
    # í…ìŠ¤íŠ¸ í† í°í™”
    encoding = tokenizer(
        text,
        max_length=max_length,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs['logits']
        probabilities = torch.softmax(logits, dim=-1)
        predicted_label = torch.argmax(probabilities, dim=-1).item()
    
    probs = probabilities[0].cpu().numpy()
    emotion_eng, emotion_kor = emotion_map[predicted_label]
    
    return predicted_label, probs, emotion_eng, emotion_kor


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸')
    parser.add_argument('--model_path', type=str, required=True,
                       help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--device', type=str, default='cpu',
                       choices=['cpu', 'cuda'],
                       help='ë””ë°”ì´ìŠ¤ ì„ íƒ')
    parser.add_argument('--interactive', action='store_true',
                       help='ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ë¡œë“œ
    model, tokenizer, config = load_trained_model(args.model_path, args.device)
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
    test_texts = [
        "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„!",
        "ë„ˆë¬´ ìŠ¬í”„ê³  ìš°ìš¸í•´...",
        "ì‹œí—˜ ê²°ê³¼ê°€ ê±±ì •ë¼ì„œ ì ì´ ì•ˆ ì™€.",
        "ì •ë§ í™”ê°€ ë‚˜ì„œ ì°¸ì„ ìˆ˜ê°€ ì—†ì–´!",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë§‘ë„¤ìš”."
    ]
    
    if not args.interactive:
        # í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ ì‹¤í–‰
        print("\n" + "=" * 80)
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ")
        print("=" * 80)
        
        for text in test_texts:
            label, probs, emotion_eng, emotion_kor = predict_emotion(
                text, model, tokenizer, device
            )
            
            print(f"\nğŸ“ í…ìŠ¤íŠ¸: {text}")
            print(f"ğŸ­ ì˜ˆì¸¡ ê°ì •: {emotion_kor} ({emotion_eng}) [ë¼ë²¨: {label}]")
            print(f"ğŸ“Š í™•ë¥  ë¶„í¬:")
            for i, (eng, kor) in enumerate([('joy', 'ê¸°ì¨'), ('sad', 'ìŠ¬í””'), 
                                            ('anxiety', 'ë¶ˆì•ˆ'), ('anger', 'ë¶„ë…¸'), 
                                            ('neutral', 'ì¤‘ë¦½')]):
                bar = 'â–ˆ' * int(probs[i] * 50)
                print(f"   {kor:4s}: {bar} {probs[i]:.4f}")
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        print("\n" + "=" * 80)
        print("ğŸ’¬ ëŒ€í™”í˜• ê°ì • ë¶„ì„ ëª¨ë“œ")
        print("=" * 80)
        print("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
        
        while True:
            print("\n" + "-" * 80)
            text = input("ğŸ“ ì…ë ¥: ").strip()
            
            if text.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not text:
                continue
            
            label, probs, emotion_eng, emotion_kor = predict_emotion(
                text, model, tokenizer, device
            )
            
            print(f"\nğŸ­ ì˜ˆì¸¡ ê°ì •: {emotion_kor} ({emotion_eng})")
            print(f"ğŸ“Š í™•ë¥  ë¶„í¬:")
            for i, (eng, kor) in enumerate([('joy', 'ê¸°ì¨'), ('sad', 'ìŠ¬í””'), 
                                            ('anxiety', 'ë¶ˆì•ˆ'), ('anger', 'ë¶„ë…¸'), 
                                            ('neutral', 'ì¤‘ë¦½')]):
                bar = 'â–ˆ' * int(probs[i] * 30)
                print(f"   {kor:4s}: {bar:30s} {probs[i]:.2%}")


if __name__ == '__main__':
    main()
