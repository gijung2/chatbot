"""
ì‹œê°í™” ëª¨ë“ˆ
í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
"""
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
from typing import Dict, List
import logging

# í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rc('font', family='Malgun Gothic')  # Windows
matplotlib.rcParams['axes.unicode_minus'] = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def plot_training_history(history: Dict, save_path: str = None):
    """
    í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
    
    Args:
        history: train_loss, val_loss, val_accuracy, val_f1 í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        save_path: ê·¸ë˜í”„ ì €ì¥ ê²½ë¡œ (ì„ íƒ)
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('í•™ìŠµ ê²°ê³¼ ì‹œê°í™”', fontsize=16, fontweight='bold')
    
    epochs = range(1, len(history['train_loss']) + 1)
    
    # 1. Loss
    axes[0, 0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)
    axes[0, 0].plot(epochs, history['val_loss'], 'r-o', label='Val Loss', linewidth=2)
    axes[0, 0].set_title('Loss', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Accuracy
    axes[0, 1].plot(epochs, history['val_accuracy'], 'g-o', label='Val Accuracy', linewidth=2)
    axes[0, 1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. F1 Score
    axes[1, 0].plot(epochs, history['val_f1'], 'm-o', label='Val F1 (weighted)', linewidth=2)
    axes[1, 0].set_title('Validation F1 Score', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('F1 Score')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. ìš”ì•½ í…Œì´ë¸”
    axes[1, 1].axis('off')
    summary_text = f"""
    ğŸ“Š í•™ìŠµ ìš”ì•½
    
    â€¢ ì´ ì—í­: {len(epochs)}
    â€¢ ìµœì¢… Train Loss: {history['train_loss'][-1]:.4f}
    â€¢ ìµœì¢… Val Loss: {history['val_loss'][-1]:.4f}
    â€¢ ìµœì¢… Val Accuracy: {history['val_accuracy'][-1]:.4f}
    â€¢ ìµœì¢… Val F1: {history['val_f1'][-1]:.4f}
    
    â€¢ Best Val Loss: {min(history['val_loss']):.4f} (Epoch {np.argmin(history['val_loss'])+1})
    â€¢ Best Val Accuracy: {max(history['val_accuracy']):.4f} (Epoch {np.argmax(history['val_accuracy'])+1})
    â€¢ Best Val F1: {max(history['val_f1']):.4f} (Epoch {np.argmax(history['val_f1'])+1})
    """
    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=11, verticalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        logger.info(f"ğŸ’¾ ê·¸ë˜í”„ ì €ì¥: {save_path}")
    
    plt.show()
    logger.info("ğŸ“ˆ ê·¸ë˜í”„ í‘œì‹œ ì™„ë£Œ")


def plot_loss_only(train_loss: List[float], val_loss: List[float], save_path: str = None):
    """
    Lossë§Œ ê°„ë‹¨í•˜ê²Œ ì‹œê°í™”
    
    Args:
        train_loss: í•™ìŠµ ì†ì‹¤ ë¦¬ìŠ¤íŠ¸
        val_loss: ê²€ì¦ ì†ì‹¤ ë¦¬ìŠ¤íŠ¸
        save_path: ì €ì¥ ê²½ë¡œ
    """
    plt.figure(figsize=(10, 6))
    epochs = range(1, len(train_loss) + 1)
    
    plt.plot(epochs, train_loss, 'b-o', label='Training Loss', linewidth=2, markersize=8)
    plt.plot(epochs, val_loss, 'r-o', label='Validation Loss', linewidth=2, markersize=8)
    
    plt.title('Training and Validation Loss', fontsize=16, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        logger.info(f"ğŸ’¾ Loss ê·¸ë˜í”„ ì €ì¥: {save_path}")
    
    plt.show()
