# ê°ì • ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”
ì´ ë””ë ‰í† ë¦¬ëŠ” ê°ì • ë¶„ë¥˜ ëª¨ë¸(KLUE/KoBERT)ì„ VSCodeì—ì„œ í•™ìŠµí•˜ê¸° ìœ„í•œ ëª¨ë“ˆí™”ëœ ì½”ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ—‚ï¸ íŒŒì¼ êµ¬ì¡°
```
training/
â”œâ”€â”€ main.py                      # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (CLI)
â”œâ”€â”€ data_loader.py               # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
â”œâ”€â”€ model.py                     # ëª¨ë¸ ì •ì˜ (KLUE/KoBERT)
â”œâ”€â”€ train.py                     # í•™ìŠµ ë° ê²€ì¦ ë¡œì§
â”œâ”€â”€ visualize.py                 # í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
â”œâ”€â”€ requirements_training.txt    # í•™ìŠµìš© íŒ¨í‚¤ì§€ ìš”êµ¬ì‚¬í•­
â””â”€â”€ README.md                    # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜
```powershell
pip install -r training\requirements_training.txt
```

### 2. ê¸°ë³¸ í•™ìŠµ ì‹¤í–‰
```powershell
python training\main.py --mode train --batch_size 16 --epochs 10
```

### 3. ë°°ì¹˜ í¬ê¸°ì™€ ì—í­ ì¡°ì •
```powershell
# ë°°ì¹˜ 32, ì—í­ 5ë¡œ í•™ìŠµ
python training\main.py --mode train --batch_size 32 --epochs 5

# GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ ë°°ì¹˜ë¥¼ ì¤„ì´ì„¸ìš”
python training\main.py --mode train --batch_size 8 --epochs 10
```

## ğŸ›ï¸ ì£¼ìš” ì»¤ë§¨ë“œ ë¼ì¸ ì˜µì…˜

### í•™ìŠµ ëª¨ë“œ
```powershell
python training\main.py --mode train \
    --batch_size 16 \
    --epochs 10 \
    --learning_rate 2e-5 \
    --model_name klue/bert-base \
    --output_dir checkpoints \
    --save_history
```

### í‰ê°€ ëª¨ë“œ
```powershell
python training\main.py --mode evaluate \
    --model_path checkpoints/best_model_20250228_123456.pt \
    --batch_size 32
```

## ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `--batch_size` | 16 | ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •) |
| `--epochs` | 10 | í•™ìŠµ ì—í­ ìˆ˜ |
| `--learning_rate` | 2e-5 | í•™ìŠµë¥  |
| `--max_length` | 128 | ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ |
| `--dropout_rate` | 0.3 | Dropout ë¹„ìœ¨ |
| `--early_stopping_patience` | 3 | Early stopping ì¸ë‚´ì‹¬ |

## ğŸ’¾ ì¶œë ¥ íŒŒì¼

í•™ìŠµ ì™„ë£Œ í›„ `checkpoints/` ë””ë ‰í† ë¦¬ì— ìƒì„±ë˜ëŠ” íŒŒì¼:
- `best_model_YYYYMMDD_HHMMSS.pt` - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
- `history_YYYYMMDD_HHMMSS.json` - í•™ìŠµ íˆìŠ¤í† ë¦¬ (--save_history ì˜µì…˜)
- `training_history_YYYYMMDD_HHMMSS.png` - í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„

## ğŸ–¥ï¸ GPU/CPU ì‚¬ìš©

- **GPU ì‚¬ìš©**: CUDAê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- **CPUë§Œ ì‚¬ìš©**: GPUê°€ ì—†ì–´ë„ ì •ìƒ ì‘ë™í•˜ì§€ë§Œ ëŠë¦½ë‹ˆë‹¤.
- **GPU í™•ì¸**:
  ```powershell
  python -c "import torch; print('CUDA:', torch.cuda.is_available())"
  ```

## ğŸ“ˆ í•™ìŠµ ëª¨ë‹ˆí„°ë§

í•™ìŠµ ì¤‘ì—ëŠ” ë‹¤ìŒ ì •ë³´ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤:
- Train Loss (ì—í­ë³„)
- Validation Loss
- Validation Accuracy
- Validation F1 Score (weighted)
- í´ë˜ìŠ¤ë³„ Precision, Recall, F1

í•™ìŠµ ì™„ë£Œ í›„ ê·¸ë˜í”„ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë˜ê³  í‘œì‹œë©ë‹ˆë‹¤.

## ğŸ”§ ë¬¸ì œ í•´ê²°

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```powershell
# ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ì„¸ìš”
python training\main.py --batch_size 8 --epochs 10
```

### í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼
```powershell
# ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¤„ì´ì„¸ìš”
python training\main.py --max_length 64 --batch_size 32
```

### KoBERT ì‚¬ìš©
```powershell
# kobert-tokenizer ì„¤ì¹˜ í›„
python training\main.py --model_name skt/kobert-base-v1
```

## ğŸ“ ì˜ˆì œ ëª…ë ¹ì–´

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì‘ì€ ì—í­)
```powershell
python training\main.py --mode train --batch_size 32 --epochs 3
```

### ì™„ì „ í•™ìŠµ (í° ë°°ì¹˜, ê¸´ ì—í­)
```powershell
python training\main.py --mode train --batch_size 32 --epochs 20 --early_stopping_patience 5 --save_history
```

### BERT íŒŒë¼ë¯¸í„° ë™ê²° (ë¶„ë¥˜ í—¤ë“œë§Œ í•™ìŠµ)
```powershell
python training\main.py --mode train --freeze_bert --epochs 5
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. í•™ìŠµ ì™„ë£Œ í›„ `checkpoints/best_model_*.pt` íŒŒì¼ì„ `kobert_psychological_api.py`ì— í†µí•©
2. í‰ê°€ ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥ í™•ì¸
3. í”„ë¡ íŠ¸ì—”ë“œì™€ ì—°ê²°í•˜ì—¬ ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ë°ëª¨ êµ¬ì¶•

## ğŸ“š ì°¸ê³ 

- [Hugging Face Transformers ë¬¸ì„œ](https://huggingface.co/docs/transformers)
- [KLUE ë²¤ì¹˜ë§ˆí¬](https://klue-benchmark.com/)
- [PyTorch íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/)
