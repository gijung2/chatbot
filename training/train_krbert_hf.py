"""
KR-BERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ í•™ìŠµ (Hugging Face Trainer ì‚¬ìš©)
ì œê³µëœ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ í˜„ìž¬ í”„ë¡œì íŠ¸ì— ìµœì í™”

í†µí•© ë°ì´í„°ì…‹ ì‚¬ìš© (131K samples):
- ê¸°ì¡´ ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜ (41K)
- í•œêµ­ì–´_ë‹¨ë°œì„±_ëŒ€í™”_ë°ì´í„°ì…‹ (38K)
- í•œêµ­ì–´_ì—°ì†ì _ëŒ€í™”_ë°ì´í„°ì…‹ (55K)

ì‚¬ìš©ë²•:
    # í†µí•© ë°ì´í„° (ê¶Œìž¥)
    python training/train_krbert_hf.py --data_path data/processed/emotion_corpus_merged.csv --epochs 12 --batch_size 64 --k_folds 2
    
    # ê¸°ì¡´ ë°ì´í„°ë§Œ
    python training/train_krbert_hf.py --data_path data/processed/emotion_corpus_full.csv --epochs 12 --batch_size 64
"""
import argparse
import os
import numpy as np
import pandas as pd
import torch
from datetime import datetime

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
from sklearn.preprocessing import LabelEncoder

from torch.utils.data import Dataset

from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    AutoConfig,
    BertForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)

import torch.nn as nn
import logging
import json
import gc

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì • (ë¶ˆê· í˜• ë°ì´í„° ë³´ì •)
# ê°€ì¤‘ì¹˜ = ì „ì²´ ìƒ˜í”Œ ìˆ˜ / (í´ëž˜ìŠ¤ ìˆ˜ * ê° í´ëž˜ìŠ¤ ìƒ˜í”Œ ìˆ˜)
# [joy, sad, anxiety, anger, neutral]
CLASS_WEIGHTS = torch.tensor([3.01, 1.50, 1.18, 1.14, 0.48], dtype=torch.float32)


class WeightedLossBert(BertForSequenceClassification):
    """í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ CrossEntropyLossë¥¼ ì‚¬ìš©í•˜ëŠ” BERT ëª¨ë¸"""
    def __init__(self, config):
        super().__init__(config)
        
        # Loss í•¨ìˆ˜ ì •ì˜ ì‹œ class_weights ì ìš©
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.loss_fct = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS.to(device))
        logger.info(f"âœ… í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ Loss í•¨ìˆ˜ ì´ˆê¸°í™” ì™„ë£Œ (device: {device})")
        logger.info(f"   - ê°€ì¤‘ì¹˜: {CLASS_WEIGHTS.tolist()}")

    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):
        outputs = self.bert(
            input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids,
        )
        sequence_output = outputs[0]
        
        logits = self.classifier(sequence_output[:, 0, :])
        
        loss = None
        if labels is not None:
            # ì •ì˜ëœ ê°€ì¤‘ì¹˜ Loss í•¨ìˆ˜ë¡œ Loss ê³„ì‚°
            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
            
        return (loss, logits) if loss is not None else (logits,)


class EmotionDataset(Dataset):
    """Hugging Face Trainerìš© ë°ì´í„°ì…‹"""
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels is not None:
            item["labels"] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings["input_ids"])


def compute_metrics(p):
    """í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    pred, labels = p
    pred = np.argmax(pred, axis=1)

    accuracy = accuracy_score(y_true=labels, y_pred=pred)
    recall_micro = recall_score(y_true=labels, y_pred=pred, average="micro")
    recall_macro = recall_score(y_true=labels, y_pred=pred, average="macro")
    precision_micro = precision_score(y_true=labels, y_pred=pred, average="micro")
    precision_macro = precision_score(y_true=labels, y_pred=pred, average="macro")
    f1_macro = f1_score(y_true=labels, y_pred=pred, average="macro")

    return {
        "accuracy": accuracy,
        "recall_micro": recall_micro,
        "recall_macro": recall_macro,
        "precision_micro": precision_micro,
        "precision_macro": precision_macro,
        "f1_macro": f1_macro
    }


def preprocess_data(file_path, text_column, label_column, test_size, tokenizer, max_length, seed):
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    logger.info(f"\nðŸ“‚ ë°ì´í„° ë¡œë“œ: {file_path}")
    
    df = pd.read_csv(file_path)
    logger.info(f"âœ… ì´ ìƒ˜í”Œ ìˆ˜: {len(df):,}")
    
    # í…ìŠ¤íŠ¸ì™€ ë ˆì´ë¸” ì¶”ì¶œ
    X = list(df[text_column])
    
    # label_idê°€ ì´ë¯¸ ìžˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ emotionì—ì„œ ìƒì„±
    if label_column in df.columns:
        y = list(df[label_column])
    elif 'emotion' in df.columns:
        lbe = LabelEncoder()
        y = list(lbe.fit_transform(df['emotion']))
        logger.info(f"   - ë¼ë²¨ ì¸ì½”ë”©: {dict(zip(lbe.classes_, lbe.transform(lbe.classes_)))}")
    else:
        raise ValueError(f"'{label_column}' ë˜ëŠ” 'emotion' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # í´ëž˜ìŠ¤ ë¶„í¬ ì¶œë ¥
    unique, counts = np.unique(y, return_counts=True)
    logger.info(f"\nðŸ“Š í´ëž˜ìŠ¤ ë¶„í¬:")
    for label_id, count in zip(unique, counts):
        percentage = count / len(y) * 100
        logger.info(f"   - Class {label_id}: {count:,} ({percentage:.1f}%)")
    
    # Train/Val ë¶„í• 
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed
    )
    
    logger.info(f"\nâœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
    logger.info(f"   - Train: {len(X_train):,} samples")
    logger.info(f"   - Val: {len(X_val):,} samples")
    
    # í† í¬ë‚˜ì´ì§•
    logger.info(f"\nðŸ”¤ í† í¬ë‚˜ì´ì§• ì¤‘... (max_length={max_length})")
    X_train_tokenized = tokenizer(
        X_train, padding=True, truncation=True, max_length=max_length
    )
    X_val_tokenized = tokenizer(
        X_val, padding=True, truncation=True, max_length=max_length
    )
    logger.info(f"âœ… í† í¬ë‚˜ì´ì§• ì™„ë£Œ")
    
    return X_train_tokenized, X_val_tokenized, y_train, y_val


def train_kfold(args):
    """K-Fold Cross Validation í•™ìŠµ"""
    logger.info("\n" + "=" * 80)
    logger.info(f"ðŸ”€ {args.k_folds}-Fold Cross Validation ì‹œìž‘")
    logger.info("=" * 80)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(args.data_path)
    X = list(df[args.text_column])
    
    if args.label_column in df.columns:
        y = np.array(df[args.label_column])
    elif 'emotion' in df.columns:
        lbe = LabelEncoder()
        y = lbe.fit_transform(df['emotion'])
    else:
        raise ValueError(f"'{args.label_column}' ë˜ëŠ” 'emotion' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    logger.info(f"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ: {args.model_name}")
    
    # K-Fold ë¶„í• 
    skf = StratifiedKFold(n_splits=args.k_folds, shuffle=True, random_state=args.seed)
    
    all_fold_results = []
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        logger.info("\n" + "=" * 80)
        logger.info(f"ðŸ“Š Fold {fold_idx + 1}/{args.k_folds} í•™ìŠµ ì‹œìž‘")
        logger.info("=" * 80)
        
        # Fold ë°ì´í„° ì¤€ë¹„
        X_train = [X[i] for i in train_idx]
        X_val = [X[i] for i in val_idx]
        y_train = y[train_idx].tolist()
        y_val = y[val_idx].tolist()
        
        logger.info(f"   - Train: {len(X_train):,} samples")
        logger.info(f"   - Val: {len(X_val):,} samples")
        
        # í† í¬ë‚˜ì´ì§•
        X_train_tokenized = tokenizer(
            X_train, padding=True, truncation=True, max_length=args.max_length
        )
        X_val_tokenized = tokenizer(
            X_val, padding=True, truncation=True, max_length=args.max_length
        )
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = EmotionDataset(X_train_tokenized, y_train)
        val_dataset = EmotionDataset(X_val_tokenized, y_val)
        
        # í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ (ê° foldë§ˆë‹¤ ìƒˆë¡œ ì´ˆê¸°í™”)
        logger.info(f"\nðŸ¤– ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ: {args.model_name}")
        config = AutoConfig.from_pretrained(args.model_name, num_labels=args.num_labels)
        model = WeightedLossBert.from_pretrained(args.model_name, config=config)
        logger.info(f"âœ… í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # Training Arguments (transformers ìµœì‹  ë²„ì „ í˜¸í™˜)
        output_dir = os.path.join(args.output_dir, f"fold{fold_idx+1}_{timestamp}")
        training_args = TrainingArguments(
            output_dir=output_dir,
            eval_strategy="steps",  # evaluation_strategyì—ì„œ ë³€ê²½
            eval_steps=args.eval_steps,
            per_device_train_batch_size=args.batch_size,
            per_device_eval_batch_size=args.batch_size,
            num_train_epochs=args.epochs,
            seed=args.seed,
            load_best_model_at_end=True,
            learning_rate=args.learning_rate,
            save_total_limit=1,
            logging_steps=100,
            save_strategy="steps",
            save_steps=args.eval_steps,
            metric_for_best_model="f1_macro",
            greater_is_better=True,
            warmup_steps=args.warmup_steps,
            weight_decay=0.01,
            fp16=False,  # CPU ëª¨ë“œì—ì„œëŠ” False
        )
        
        # Trainer ìƒì„±
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=args.early_stopping_patience)]
            if args.early_stopping_patience > 0 else None,
        )
        
        # í•™ìŠµ
        logger.info(f"\nðŸš€ Fold {fold_idx + 1} í•™ìŠµ ì‹œìž‘...")
        train_result = trainer.train()
        
        # í‰ê°€
        eval_result = trainer.evaluate()
        
        logger.info(f"\nðŸ“Š Fold {fold_idx + 1} ê²°ê³¼:")
        logger.info(f"   - Accuracy: {eval_result['eval_accuracy']:.4f}")
        logger.info(f"   - F1 Macro: {eval_result['eval_f1_macro']:.4f}")
        logger.info(f"   - Precision Macro: {eval_result['eval_precision_macro']:.4f}")
        logger.info(f"   - Recall Macro: {eval_result['eval_recall_macro']:.4f}")
        
        # ëª¨ë¸ ì €ìž¥
        model_path = os.path.join(args.output_dir, f"fold{fold_idx+1}_best_model_{timestamp}")
        trainer.save_model(model_path)
        logger.info(f"ðŸ’¾ ëª¨ë¸ ì €ìž¥: {model_path}")
        
        # ê²°ê³¼ ê¸°ë¡
        fold_results = {
            'fold': fold_idx + 1,
            'accuracy': eval_result['eval_accuracy'],
            'f1_macro': eval_result['eval_f1_macro'],
            'precision_macro': eval_result['eval_precision_macro'],
            'recall_macro': eval_result['eval_recall_macro'],
            'loss': eval_result['eval_loss'],
            'model_path': model_path
        }
        all_fold_results.append(fold_results)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del model, trainer
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "=" * 80)
    logger.info(f"ðŸ“Š {args.k_folds}-Fold Cross Validation ìµœì¢… ê²°ê³¼")
    logger.info("=" * 80)
    
    avg_acc = np.mean([r['accuracy'] for r in all_fold_results])
    std_acc = np.std([r['accuracy'] for r in all_fold_results])
    avg_f1 = np.mean([r['f1_macro'] for r in all_fold_results])
    std_f1 = np.std([r['f1_macro'] for r in all_fold_results])
    
    logger.info(f"\nðŸ“ˆ í‰ê·  ì„±ëŠ¥:")
    logger.info(f"   - Accuracy: {avg_acc:.4f} Â± {std_acc:.4f}")
    logger.info(f"   - F1 Macro: {avg_f1:.4f} Â± {std_f1:.4f}")
    
    # ìµœê³  ì„±ëŠ¥ fold
    best_fold_idx = np.argmax([r['f1_macro'] for r in all_fold_results])
    best_fold = all_fold_results[best_fold_idx]
    
    logger.info(f"\nðŸ† ìµœê³  ì„±ëŠ¥ Fold: {best_fold['fold']}")
    logger.info(f"   - Accuracy: {best_fold['accuracy']:.4f}")
    logger.info(f"   - F1 Macro: {best_fold['f1_macro']:.4f}")
    logger.info(f"   - ëª¨ë¸ ê²½ë¡œ: {best_fold['model_path']}")
    
    # ê²°ê³¼ ì €ìž¥
    results_summary = {
        'timestamp': timestamp,
        'k_folds': args.k_folds,
        'avg_accuracy': float(avg_acc),
        'std_accuracy': float(std_acc),
        'avg_f1_macro': float(avg_f1),
        'std_f1_macro': float(std_f1),
        'best_fold': int(best_fold['fold']),
        'fold_results': all_fold_results
    }
    
    summary_path = os.path.join(args.output_dir, f'kfold_summary_{timestamp}.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nðŸ’¾ ê²°ê³¼ ìš”ì•½ ì €ìž¥: {summary_path}")
    
    return all_fold_results


def train_single(args):
    """ë‹¨ì¼ Train/Val split í•™ìŠµ"""
    logger.info("\n" + "=" * 80)
    logger.info("ðŸš€ ë‹¨ì¼ Train/Val í•™ìŠµ ì‹œìž‘")
    logger.info("=" * 80)
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    logger.info(f"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ: {args.model_name}")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    X_train_tokenized, X_val_tokenized, y_train, y_val = preprocess_data(
        file_path=args.data_path,
        text_column=args.text_column,
        label_column=args.label_column,
        test_size=args.test_size,
        tokenizer=tokenizer,
        max_length=args.max_length,
        seed=args.seed
    )
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = EmotionDataset(X_train_tokenized, y_train)
    val_dataset = EmotionDataset(X_val_tokenized, y_val)
    
    # í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ
    logger.info(f"\nðŸ¤– ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ: {args.model_name}")
    config = AutoConfig.from_pretrained(args.model_name, num_labels=args.num_labels)
    model = WeightedLossBert.from_pretrained(args.model_name, config=config)
    logger.info(f"âœ… í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (num_labels={args.num_labels})")
    
    # Training Arguments (transformers ìµœì‹  ë²„ì „ í˜¸í™˜)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(args.output_dir, f"single_{timestamp}")
    
    training_args = TrainingArguments(
        output_dir=output_dir,
        eval_strategy="steps",  # evaluation_strategyì—ì„œ ë³€ê²½
        eval_steps=args.eval_steps,
        per_device_train_batch_size=args.batch_size,
        per_device_eval_batch_size=args.batch_size,
        num_train_epochs=args.epochs,
        seed=args.seed,
        load_best_model_at_end=True,
        learning_rate=args.learning_rate,
        save_total_limit=1,
        logging_steps=100,
        save_strategy="steps",
        save_steps=args.eval_steps,
        metric_for_best_model="f1_macro",
        greater_is_better=True,
        warmup_steps=args.warmup_steps,
        weight_decay=0.01,
        fp16=False,  # CPU ëª¨ë“œ
    )
    
    # Trainer ìƒì„±
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=args.early_stopping_patience)]
        if args.early_stopping_patience > 0 else None,
    )
    
    # í•™ìŠµ
    logger.info("\nðŸš€ í•™ìŠµ ì‹œìž‘...")
    trainer.train()
    
    # ìµœì¢… í‰ê°€
    eval_result = trainer.evaluate()
    
    logger.info("\n" + "=" * 80)
    logger.info("ðŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
    logger.info("=" * 80)
    logger.info(f"   - Accuracy: {eval_result['eval_accuracy']:.4f}")
    logger.info(f"   - F1 Macro: {eval_result['eval_f1_macro']:.4f}")
    logger.info(f"   - Precision Macro: {eval_result['eval_precision_macro']:.4f}")
    logger.info(f"   - Recall Macro: {eval_result['eval_recall_macro']:.4f}")
    logger.info(f"   - Loss: {eval_result['eval_loss']:.4f}")
    
    # ëª¨ë¸ ì €ìž¥
    model_path = os.path.join(args.output_dir, f"best_model_{timestamp}")
    trainer.save_model(model_path)
    tokenizer.save_pretrained(model_path)
    logger.info(f"\nðŸ’¾ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ìž¥: {model_path}")
    
    # ê²°ê³¼ ì €ìž¥
    results = {
        'timestamp': timestamp,
        'model_name': args.model_name,
        'accuracy': eval_result['eval_accuracy'],
        'f1_macro': eval_result['eval_f1_macro'],
        'precision_macro': eval_result['eval_precision_macro'],
        'recall_macro': eval_result['eval_recall_macro'],
        'loss': eval_result['eval_loss'],
        'model_path': model_path,
        'hyperparameters': vars(args)
    }
    
    results_path = os.path.join(args.output_dir, f'results_{timestamp}.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ðŸ’¾ ê²°ê³¼ ì €ìž¥: {results_path}")
    logger.info("\nâœ… í•™ìŠµ ì™„ë£Œ!")


def parse_args():
    """ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìž íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='KR-BERT ê°ì • ë¶„ë¥˜ í•™ìŠµ')
    
    # ë°ì´í„°
    parser.add_argument('--data_path', type=str,
                        default='data/processed/emotion_corpus_merged.csv',
                        help='ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸: í†µí•© ë°ì´í„° 131K samples)')
    parser.add_argument('--text_column', type=str, default='text',
                        help='í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…')
    parser.add_argument('--label_column', type=str, default='label_id',
                        help='ë¼ë²¨ ì»¬ëŸ¼ëª…')
    parser.add_argument('--test_size', type=float, default=0.05,
                        help='Validation ë¹„ìœ¨ (ê¸°ë³¸: 0.05)')
    
    # K-Fold ì˜µì…˜
    parser.add_argument('--k_folds', type=int, default=0,
                        help='K-Fold ìˆ˜ (0ì´ë©´ ë‹¨ì¼ train/val split)')
    
    # ëª¨ë¸
    parser.add_argument('--model_name', type=str,
                        default='snunlp/KR-Medium',
                        help='Hugging Face ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: snunlp/KR-Medium)')
    parser.add_argument('--num_labels', type=int, default=5,
                        help='ê°ì • í´ëž˜ìŠ¤ ìˆ˜ (ê¸°ë³¸: 5)')
    
    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    parser.add_argument('--batch_size', type=int, default=64,
                        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)')
    parser.add_argument('--epochs', type=int, default=7,
                        help='ì—í­ ìˆ˜ (ê¸°ë³¸: 7)')
    parser.add_argument('--learning_rate', type=float, default=5e-5,
                        help='í•™ìŠµë¥  (ê¸°ë³¸: 5e-5)')
    parser.add_argument('--max_length', type=int, default=128,
                        help='ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê¸°ë³¸: 128)')
    parser.add_argument('--warmup_steps', type=int, default=0,
                        help='Warmup ìŠ¤í… ìˆ˜')
    parser.add_argument('--eval_steps', type=int, default=500,
                        help='í‰ê°€ ì£¼ê¸° (ê¸°ë³¸: 500)')
    parser.add_argument('--early_stopping_patience', type=int, default=3,
                        help='Early stopping ì¸ë‚´ì‹¬ (0ì´ë©´ ë¹„í™œì„±í™”)')
    
    # ì €ìž¥
    parser.add_argument('--output_dir', type=str, default='checkpoints_krbert',
                        help='ëª¨ë¸ ì €ìž¥ ë””ë ‰í† ë¦¬')
    
    # ê¸°íƒ€
    parser.add_argument('--seed', type=int, default=42,
                        help='ëžœë¤ ì‹œë“œ')
    
    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ì„¤ì • ì¶œë ¥
    logger.info("\n" + "=" * 80)
    logger.info("âš™ï¸ KR-BERT ê°ì • ë¶„ë¥˜ í•™ìŠµ ì„¤ì •")
    logger.info("=" * 80)
    for arg, value in vars(args).items():
        logger.info(f"   - {arg}: {value}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # K-Fold ë˜ëŠ” ë‹¨ì¼ í•™ìŠµ
    if args.k_folds > 1:
        train_kfold(args)
    else:
        train_single(args)


if __name__ == "__main__":
    main()
