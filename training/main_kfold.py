"""
K-Fold Cross Validation ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ê°ì • ë¶„ë¥˜ ëª¨ë¸ K-fold êµì°¨ê²€ì¦ í•™ìŠµ

ì‚¬ìš©ë²•:
    python training/main_kfold.py --data_path data/processed/emotion_corpus_full.csv --k_folds 5 --epochs 10
"""
import argparse
import os
import torch
from transformers import AutoTokenizer
import logging
import json
from datetime import datetime
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score

from data_loader import EmotionDataset
from model import create_model
from train import Trainer
from visualize import plot_training_history

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_args():
    """ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='K-Fold ê°ì • ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ')
    
    # ë°ì´í„°
    parser.add_argument('--data_path', type=str,
                        default='data/processed/emotion_corpus_full.csv',
                        help='ì „ì²´ ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--text_column', type=str, default='text',
                        help='í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…')
    parser.add_argument('--label_column', type=str, default='label_id',
                        help='ë¼ë²¨ ì»¬ëŸ¼ëª…')
    parser.add_argument('--k_folds', type=int, default=5,
                        help='K-Fold ìˆ˜ (ê¸°ë³¸: 5)')
    
    # ëª¨ë¸
    parser.add_argument('--model_name', type=str,
                        default='klue/bert-base',
                        help='Hugging Face ëª¨ë¸ ì´ë¦„')
    parser.add_argument('--num_labels', type=int, default=5,
                        help='ê°ì • í´ë˜ìŠ¤ ìˆ˜')
    parser.add_argument('--dropout_rate', type=float, default=0.3,
                        help='Dropout ë¹„ìœ¨')
    parser.add_argument('--freeze_bert', action='store_true',
                        help='BERT íŒŒë¼ë¯¸í„° ë™ê²°')
    
    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    parser.add_argument('--batch_size', type=int, default=16,
                        help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=10,
                        help='ì—í­ ìˆ˜')
    parser.add_argument('--learning_rate', type=float, default=2e-5,
                        help='í•™ìŠµë¥ ')
    parser.add_argument('--max_length', type=int, default=128,
                        help='ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´')
    parser.add_argument('--warmup_steps', type=int, default=0,
                        help='Warmup ìŠ¤í… ìˆ˜')
    parser.add_argument('--max_grad_norm', type=float, default=1.0,
                        help='Gradient clipping ì„ê³„ê°’')
    parser.add_argument('--early_stopping_patience', type=int, default=3,
                        help='Early stopping ì¸ë‚´ì‹¬')
    
    # ì €ì¥
    parser.add_argument('--output_dir', type=str, default='checkpoints_kfold',
                        help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--save_all_folds', action='store_true',
                        help='ëª¨ë“  fold ëª¨ë¸ ì €ì¥ (ê¸°ë³¸: ìµœê³  foldë§Œ)')
    
    # ê¸°íƒ€
    parser.add_argument('--num_workers', type=int, default=0,
                        help='ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜')
    parser.add_argument('--seed', type=int, default=42,
                        help='ëœë¤ ì‹œë“œ')
    
    return parser.parse_args()


def set_seed(seed: int):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    import random
    import numpy as np
    random.seed(seed)
    np.random.seed(seed)
    logger.info(f"ğŸŒ± ì‹œë“œ ì„¤ì •: {seed}")


def create_kfold_splits(df: pd.DataFrame, k_folds: int, label_column: str, seed: int):
    """Stratified K-Fold ë¶„í•  ìƒì„±"""
    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)
    splits = []
    
    X = df.index.values
    y = df[label_column].values
    
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        splits.append((train_idx, val_idx))
        logger.info(f"   Fold {fold_idx+1}: Train={len(train_idx):,}, Val={len(val_idx):,}")
    
    return splits


def train_single_fold(
    fold_idx: int,
    train_df: pd.DataFrame,
    val_df: pd.DataFrame,
    args,
    tokenizer,
    device,
    timestamp: str
):
    """ë‹¨ì¼ Fold í•™ìŠµ"""
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ“Š Fold {fold_idx + 1}/{args.k_folds} í•™ìŠµ ì‹œì‘")
    logger.info("=" * 80)
    
    # DataLoader ìƒì„±
    from torch.utils.data import DataLoader
    
    train_dataset = EmotionDataset(
        texts=train_df[args.text_column].values,
        labels=train_df[args.label_column].values,
        tokenizer=tokenizer,
        max_length=args.max_length
    )
    
    val_dataset = EmotionDataset(
        texts=val_df[args.text_column].values,
        labels=val_df[args.label_column].values,
        tokenizer=tokenizer,
        max_length=args.max_length
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers
    )
    
    logger.info(f"âœ… Train batches: {len(train_loader)}, Val batches: {len(val_loader)}")
    
    # ëª¨ë¸ ìƒì„± (ê° foldë§ˆë‹¤ ìƒˆë¡œ ì´ˆê¸°í™”)
    model = create_model(
        model_name=args.model_name,
        num_labels=args.num_labels,
        dropout_rate=args.dropout_rate,
        freeze_bert=args.freeze_bert,
        device=device
    )
    
    # Trainer ìƒì„±
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        learning_rate=args.learning_rate,
        warmup_steps=args.warmup_steps,
        max_grad_norm=args.max_grad_norm
    )
    
    # í•™ìŠµ ì‹¤í–‰
    save_path = os.path.join(
        args.output_dir, 
        f'fold{fold_idx+1}_model_{timestamp}.pt'
    )
    
    history = trainer.train(
        num_epochs=args.epochs,
        save_path=save_path,
        early_stopping_patience=args.early_stopping_patience
    )
    
    # ìµœê³  ì„±ëŠ¥ ê¸°ë¡
    best_epoch = np.argmax(history['val_f1'])
    fold_results = {
        'fold': fold_idx + 1,
        'best_val_acc': history['val_acc'][best_epoch],
        'best_val_f1': history['val_f1'][best_epoch],
        'best_val_loss': history['val_loss'][best_epoch],
        'best_epoch': best_epoch + 1,
        'model_path': save_path,
        'history': history
    }
    
    logger.info(f"\nğŸ“Š Fold {fold_idx + 1} ê²°ê³¼:")
    logger.info(f"   - Best Epoch: {fold_results['best_epoch']}")
    logger.info(f"   - Best Val Acc: {fold_results['best_val_acc']:.4f}")
    logger.info(f"   - Best Val F1: {fold_results['best_val_f1']:.4f}")
    logger.info(f"   - Best Val Loss: {fold_results['best_val_loss']:.4f}")
    
    return fold_results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ì‹œë“œ ê³ ì •
    set_seed(args.seed)
    
    # ì„¤ì • ì¶œë ¥
    logger.info("\n" + "=" * 80)
    logger.info("âš™ï¸ K-Fold Cross Validation ì„¤ì •")
    logger.info("=" * 80)
    for arg, value in vars(args).items():
        logger.info(f"   - {arg}: {value}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"\nğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")
    if torch.cuda.is_available():
        logger.info(f"   - GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"   - CUDA ë²„ì „: {torch.version.cuda}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ë°ì´í„° ë¡œë“œ
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‚ ì „ì²´ ë°ì´í„° ë¡œë“œ")
    logger.info("=" * 80)
    logger.info(f"   - ê²½ë¡œ: {args.data_path}")
    
    df = pd.read_csv(args.data_path)
    logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,} samples")
    logger.info(f"   - ì»¬ëŸ¼: {list(df.columns)}")
    
    # í´ë˜ìŠ¤ ë¶„í¬
    logger.info(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
    for label_id in sorted(df[args.label_column].unique()):
        count = (df[args.label_column] == label_id).sum()
        percentage = count / len(df) * 100
        emotion = df[df[args.label_column] == label_id]['emotion'].iloc[0] if 'emotion' in df.columns else label_id
        logger.info(f"   - {emotion} (id={label_id}): {count:,} ({percentage:.1f}%)")
    
    # K-Fold ë¶„í•  ìƒì„±
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ”€ {args.k_folds}-Fold Stratified ë¶„í•  ìƒì„±")
    logger.info("=" * 80)
    splits = create_kfold_splits(
        df=df,
        k_folds=args.k_folds,
        label_column=args.label_column,
        seed=args.seed
    )
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë“œ")
    logger.info("=" * 80)
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    logger.info(f"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ: {args.model_name}")
    
    # K-Fold í•™ìŠµ ì‹¤í–‰
    all_fold_results = []
    
    for fold_idx, (train_idx, val_idx) in enumerate(splits):
        train_df = df.iloc[train_idx].reset_index(drop=True)
        val_df = df.iloc[val_idx].reset_index(drop=True)
        
        fold_results = train_single_fold(
            fold_idx=fold_idx,
            train_df=train_df,
            val_df=val_df,
            args=args,
            tokenizer=tokenizer,
            device=device,
            timestamp=timestamp
        )
        
        all_fold_results.append(fold_results)
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ“Š {args.k_folds}-Fold Cross Validation ìµœì¢… ê²°ê³¼")
    logger.info("=" * 80)
    
    avg_acc = np.mean([r['best_val_acc'] for r in all_fold_results])
    std_acc = np.std([r['best_val_acc'] for r in all_fold_results])
    avg_f1 = np.mean([r['best_val_f1'] for r in all_fold_results])
    std_f1 = np.std([r['best_val_f1'] for r in all_fold_results])
    avg_loss = np.mean([r['best_val_loss'] for r in all_fold_results])
    
    logger.info(f"\nğŸ“ˆ í‰ê·  ì„±ëŠ¥:")
    logger.info(f"   - Accuracy: {avg_acc:.4f} Â± {std_acc:.4f}")
    logger.info(f"   - F1 Score: {avg_f1:.4f} Â± {std_f1:.4f}")
    logger.info(f"   - Loss: {avg_loss:.4f}")
    
    logger.info(f"\nğŸ“‹ Foldë³„ ìƒì„¸ ê²°ê³¼:")
    for result in all_fold_results:
        logger.info(f"   Fold {result['fold']}: "
                   f"Acc={result['best_val_acc']:.4f}, "
                   f"F1={result['best_val_f1']:.4f}, "
                   f"Loss={result['best_val_loss']:.4f}, "
                   f"Epoch={result['best_epoch']}")
    
    # ìµœê³  ì„±ëŠ¥ fold ì°¾ê¸°
    best_fold_idx = np.argmax([r['best_val_f1'] for r in all_fold_results])
    best_fold = all_fold_results[best_fold_idx]
    
    logger.info(f"\nğŸ† ìµœê³  ì„±ëŠ¥ Fold: {best_fold['fold']}")
    logger.info(f"   - Accuracy: {best_fold['best_val_acc']:.4f}")
    logger.info(f"   - F1 Score: {best_fold['best_val_f1']:.4f}")
    logger.info(f"   - ëª¨ë¸ ê²½ë¡œ: {best_fold['model_path']}")
    
    # ê²°ê³¼ ì €ì¥
    results_summary = {
        'timestamp': timestamp,
        'k_folds': args.k_folds,
        'total_samples': len(df),
        'avg_accuracy': float(avg_acc),
        'std_accuracy': float(std_acc),
        'avg_f1': float(avg_f1),
        'std_f1': float(std_f1),
        'avg_loss': float(avg_loss),
        'best_fold': int(best_fold['fold']),
        'best_fold_acc': float(best_fold['best_val_acc']),
        'best_fold_f1': float(best_fold['best_val_f1']),
        'fold_results': [
            {
                'fold': r['fold'],
                'best_val_acc': float(r['best_val_acc']),
                'best_val_f1': float(r['best_val_f1']),
                'best_val_loss': float(r['best_val_loss']),
                'best_epoch': r['best_epoch'],
                'model_path': r['model_path']
            }
            for r in all_fold_results
        ]
    }
    
    summary_path = os.path.join(args.output_dir, f'kfold_summary_{timestamp}.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ’¾ ê²°ê³¼ ìš”ì•½ ì €ì¥: {summary_path}")
    
    # ìµœê³  ì„±ëŠ¥ foldì˜ í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    graph_path = os.path.join(args.output_dir, f'best_fold_history_{timestamp}.png')
    plot_training_history(best_fold['history'], save_path=graph_path)
    logger.info(f"ğŸ“ˆ ìµœê³  ì„±ëŠ¥ Fold ê·¸ë˜í”„ ì €ì¥: {graph_path}")
    
    # ìµœê³  ì„±ëŠ¥ foldê°€ ì•„ë‹Œ ëª¨ë¸ ì‚­ì œ (ì˜µì…˜)
    if not args.save_all_folds:
        logger.info(f"\nğŸ—‘ï¸ ìµœê³  ì„±ëŠ¥ Fold ì™¸ ëª¨ë¸ ì‚­ì œ ì¤‘...")
        for result in all_fold_results:
            if result['fold'] != best_fold['fold']:
                if os.path.exists(result['model_path']):
                    os.remove(result['model_path'])
                    logger.info(f"   - ì‚­ì œ: {result['model_path']}")
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… K-Fold Cross Validation ì™„ë£Œ!")
    logger.info("=" * 80)


if __name__ == '__main__':
    main()
