{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb01cee9",
   "metadata": {},
   "source": [
    "# ğŸš€ KR-BERT ê°ì • ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (Google Colab)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Google Colabì˜ **ë¬´ë£Œ GPU**ë¥¼ ì‚¬ìš©í•˜ì—¬ KR-BERT ê¸°ë°˜ ê°ì • ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ëª¨ë¸**: snunlp/KR-Medium (ë˜ëŠ” snunlp/KR-BERT-char16424)  \n",
    "**ë°©ì‹**: Hugging Face Trainer (ìë™ ìµœì í™”, Early Stopping)  \n",
    "**ì˜ˆìƒ ì‹œê°„**: GPU T4 ê¸°ì¤€ **2-3ì‹œê°„** (CPU ëŒ€ë¹„ 8ë°° ë¹ ë¦„)\n",
    "\n",
    "## ğŸ“‹ ì‹¤í–‰ ìˆœì„œ\n",
    "1. **ëŸ°íƒ€ì„ ì„¤ì •**: ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > **GPU** ì„ íƒ\n",
    "2. **ì…€ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**: Shift + Enter ë˜ëŠ” ì¬ìƒ ë²„íŠ¼\n",
    "3. **ì™„ë£Œ í›„ ë‹¤ìš´ë¡œë“œ**: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "## âœ¨ íŠ¹ì§•\n",
    "- âœ… **KR-BERT**: í•œêµ­ì–´ì— ìµœì í™”ëœ BERT ëª¨ë¸\n",
    "- âœ… **Hugging Face Trainer**: ì•ˆì •ì ì¸ í•™ìŠµ, ìë™ ì²´í¬í¬ì¸íŒ…\n",
    "- âœ… **ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­**: Accuracy, Precision, Recall, F1 Score\n",
    "- âœ… **K-Fold CV**: 2-Fold Cross Validation ì§€ì›\n",
    "- âœ… **Early Stopping**: ê³¼ì í•© ë°©ì§€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2dcbde",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ GPU í™•ì¸ ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ca8e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ PyTorch ë²„ì „: 2.9.0+cpu\n",
      "ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: False\n",
      "âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPUë¥¼ ì„ íƒí•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "import torch\n",
    "print(f\"ğŸ–¥ï¸ PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ“Š GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPUë¥¼ ì„ íƒí•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b2321",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a776b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install transformers>=4.30.0 datasets accelerate scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043801d",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ë°ì´í„° ì—…ë¡œë“œ\n",
    "\n",
    "**ë°©ë²• 1: ë¡œì»¬ íŒŒì¼ ì—…ë¡œë“œ**\n",
    "- ì™¼ìª½ íŒŒì¼ ì•„ì´ì½˜ í´ë¦­\n",
    "- `emotion_corpus_full.csv` ë“œë˜ê·¸ ì•¤ ë“œë¡­\n",
    "\n",
    "**ë°©ë²• 2: Google Drive ì—°ë™** (ì•„ë˜ ì…€ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜µì…˜ 1: ë¡œì»¬ì—ì„œ ì§ì ‘ ì—…ë¡œë“œ\n",
    "from google.colab import files\n",
    "print(\"ğŸ“‚ í†µí•©ëœ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
    "print(\"   - emotion_corpus_merged.csv (ê¶Œì¥, 131K samples)\")\n",
    "print(\"   - ë˜ëŠ” emotion_corpus_full.csv (ê¸°ì¡´, 41K samples)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "# í†µí•© ë°ì´í„° ìš°ì„  í™•ì¸\n",
    "if os.path.exists('emotion_corpus_merged.csv'):\n",
    "    data_path = 'emotion_corpus_merged.csv'\n",
    "    print(f\"âœ… í†µí•© ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {data_path}\")\n",
    "elif os.path.exists('emotion_corpus_full.csv'):\n",
    "    data_path = 'emotion_corpus_full.csv'\n",
    "    print(f\"âœ… ê¸°ì¡´ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {data_path}\")\n",
    "else:\n",
    "    data_path = list(uploaded.keys())[0] if uploaded else None\n",
    "    print(f\"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {data_path}\")\n",
    "\n",
    "if data_path and os.path.exists(data_path):\n",
    "    print(f\"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(data_path) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜µì…˜ 2: Google Drive ë§ˆìš´íŠ¸ (ì„ íƒì‚¬í•­)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/emotion_corpus_full.csv'  # ê²½ë¡œ ìˆ˜ì • í•„ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08601fd4",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df):,} samples\")\n",
    "print(f\"ğŸ“‹ ì»¬ëŸ¼: {df.columns.tolist()}\")\n",
    "\n",
    "# ê°ì • ë¶„í¬ í™•ì¸\n",
    "print(\"\\nğŸ“ˆ ê°ì • ë¶„í¬:\")\n",
    "if 'emotion' in df.columns:\n",
    "    emotion_counts = df['emotion'].value_counts()\n",
    "    for emotion, count in emotion_counts.items():\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"   - {emotion}: {count:,} ({percentage:.1f}%)\")\n",
    "elif 'label_id' in df.columns:\n",
    "    label_counts = df['label_id'].value_counts().sort_index()\n",
    "    emotion_names = ['joy', 'sad', 'anxiety', 'anger', 'neutral']\n",
    "    for label_id, count in label_counts.items():\n",
    "        emotion = emotion_names[label_id] if label_id < len(emotion_names) else f'label_{label_id}'\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"   - {emotion} (id={label_id}): {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ” ìƒ˜í”Œ ë°ì´í„°:\")\n",
    "print(df.head(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b6261",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ í•™ìŠµ ì½”ë“œ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œë“œ ì„¤ì •\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_seed(42)\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a828ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Trainerìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Hugging Face Trainerìš© ë°ì´í„°ì…‹\"\"\"\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜\n",
    "def compute_metrics(p):\n",
    "    \"\"\"í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚° (ì œê³µí•˜ì‹  ì½”ë“œ ê¸°ë°˜)\"\"\"\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall_micro = recall_score(y_true=labels, y_pred=pred, average=\"micro\")\n",
    "    recall_macro = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision_micro = precision_score(y_true=labels, y_pred=pred, average=\"micro\")\n",
    "    precision_macro = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1_macro = f1_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall_micro\": recall_micro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"precision_micro\": precision_micro,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"f1_macro\": f1_macro\n",
    "    }\n",
    "\n",
    "print(\"âœ… í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12fb85",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ í•™ìŠµ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42372e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ë‹¨ì¼ ë¶„í•  80/20 ë°©ì‹)\n",
    "CONFIG = {\n",
    "    'model_name': 'snunlp/KR-Medium',  # ë˜ëŠ” 'snunlp/KR-BERT-char16424', 'klue/bert-base'\n",
    "    'num_labels': 5,\n",
    "    'max_length': 128,\n",
    "    'batch_size': 64,  # GPUì—ì„œ ê°€ëŠ¥\n",
    "    'epochs': 10,  # ë‹¨ì¼ ë¶„í• ì´ë¯€ë¡œ ì—í­ ëŠ˜ë¦¼ (ë” ë§ì´ í•™ìŠµ)\n",
    "    'learning_rate': 3e-5,\n",
    "    'test_size': 0.2,  # 80/20 ë¶„í•  (Train 80%, Val 20%)\n",
    "    'early_stopping_patience': 6,\n",
    "    'eval_steps': 500,\n",
    "    'warmup_steps': 0,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(\"âš™ï¸ í•™ìŠµ ì„¤ì • (ë‹¨ì¼ ë¶„í•  80/20 ë°©ì‹):\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ“Š ë°ì´í„° ë¶„í•  ì˜ˆìƒ:\")\n",
    "total_samples = len(df) if 'df' in locals() else 131091\n",
    "train_samples = int(total_samples * (1 - CONFIG['test_size']))\n",
    "val_samples = total_samples - train_samples\n",
    "print(f\"   - Train: {train_samples:,} samples ({(1-CONFIG['test_size'])*100:.0f}%)\")\n",
    "print(f\"   - Val: {val_samples:,} samples ({CONFIG['test_size']*100:.0f}%)\")\n",
    "print(f\"   - ì´í•©: {total_samples:,} samples\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"\\nâš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPUë¥¼ ì„ íƒí•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ì •ì˜\n",
    "from transformers import BertForSequenceClassification, AutoConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "# (1) í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ í…ì„œ ì„¤ì • (ë¶ˆê· í˜• ë°ì´í„° ë³´ì •)\n",
    "# ê°€ì¤‘ì¹˜ = ì „ì²´ ìƒ˜í”Œ ìˆ˜ / (í´ë˜ìŠ¤ ìˆ˜ * ê° í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜)\n",
    "# ì†Œìˆ˜ í´ë˜ìŠ¤ì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬\n",
    "WEIGHTS = torch.tensor([3.01, 1.50, 1.18, 1.14, 0.48], dtype=torch.float32)\n",
    "\n",
    "class WeightedLossBert(BertForSequenceClassification):\n",
    "    \"\"\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ CrossEntropyLossë¥¼ ì‚¬ìš©í•˜ëŠ” BERT ëª¨ë¸\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        # (2) Loss í•¨ìˆ˜ ì •ì˜ ì‹œ class_weights ì ìš©\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loss_fct = nn.CrossEntropyLoss(weight=WEIGHTS.to(device))\n",
    "        print(f\"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ Loss í•¨ìˆ˜ ì´ˆê¸°í™” ì™„ë£Œ (device: {device})\")\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        logits = self.classifier(sequence_output[:, 0, :])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # (3) ì •ì˜ëœ ê°€ì¤‘ì¹˜ Loss í•¨ìˆ˜ë¡œ Loss ê³„ì‚°\n",
    "            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "print(\"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - ê°€ì¤‘ì¹˜: {WEIGHTS.tolist()}\")\n",
    "print(f\"   - ì„¤ëª…: [joy, sad, anxiety, anger, neutral]\")\n",
    "print(f\"   - ì†Œìˆ˜ í´ë˜ìŠ¤(joy)ì— ë†’ì€ ê°€ì¤‘ì¹˜, ë‹¤ìˆ˜ í´ë˜ìŠ¤(neutral)ì— ë‚®ì€ ê°€ì¤‘ì¹˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9efce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7ï¸âƒ£ ë‹¨ì¼ ë¶„í•  (80/20) í•™ìŠµ (Hugging Face Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af5af3",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ K-Fold Cross Validation í•™ìŠµ (Hugging Face Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ì¼ ë¶„í•  (80/20) í•™ìŠµ ì‹¤í–‰\n",
    "import time\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "texts = df['text'].values\n",
    "labels = df['label_id'].values\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸš€ ë‹¨ì¼ ë¶„í•  (80/20) í•™ìŠµ ì‹œì‘\")\n",
    "print(f\"   - ëª¨ë¸: {CONFIG['model_name']}\")\n",
    "print(f\"   - ì´ ìƒ˜í”Œ: {len(texts):,}\")\n",
    "print(f\"   - ë°°ì¹˜ í¬ê¸°: {CONFIG['batch_size']}\")\n",
    "print(f\"   - ì—í­: {CONFIG['epochs']}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train/Val ë¶„í•  (80/20, Stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=CONFIG['test_size'],\n",
    "    stratify=labels,  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ:\")\n",
    "print(f\"   - Train: {len(train_texts):,} samples ({(1-CONFIG['test_size'])*100:.0f}%)\")\n",
    "print(f\"   - Val: {len(val_texts):,} samples ({CONFIG['test_size']*100:.0f}%)\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "print(f\"\\nğŸ“ˆ Train ì„¸íŠ¸ í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "emotion_names = ['joy', 'sad', 'anxiety', 'anger', 'neutral']\n",
    "for label_id, count in zip(unique_train, counts_train):\n",
    "    emotion = emotion_names[label_id]\n",
    "    percentage = count / len(train_labels) * 100\n",
    "    print(f\"   - {emotion} (id={label_id}): {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# í† í¬ë‚˜ì´ì§•\n",
    "print(f\"\\nğŸ”¤ í† í¬ë‚˜ì´ì§• ì¤‘... (max_length={CONFIG['max_length']})\")\n",
    "train_encodings = tokenizer(\n",
    "    train_texts.tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts.tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "print(f\"âœ… í† í¬ë‚˜ì´ì§• ì™„ë£Œ\")\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels.tolist())\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "print(f\"\\nğŸ¤– ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ: {CONFIG['model_name']}\")\n",
    "config = AutoConfig.from_pretrained(CONFIG['model_name'], num_labels=CONFIG['num_labels'])\n",
    "model = WeightedLossBert.from_pretrained(CONFIG['model_name'], config=config)\n",
    "print(f\"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - ê°€ì¤‘ì¹˜ Loss í•¨ìˆ˜ë¡œ ë¶ˆê· í˜• ë°ì´í„° ë³´ì •\")\n",
    "\n",
    "# Training Arguments\n",
    "output_dir = f\"./single_split_{timestamp}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=CONFIG['eval_steps'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    num_train_epochs=CONFIG['epochs'],\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    save_total_limit=1,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=CONFIG['eval_steps'],\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,  # GPU ê°€ì†\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=CONFIG['early_stopping_patience'])]\n",
    "    if CONFIG['early_stopping_patience'] > 0 else None,\n",
    ")\n",
    "\n",
    "# í•™ìŠµ\n",
    "print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "# í‰ê°€\n",
    "print(f\"\\nğŸ“Š ìµœì¢… í‰ê°€ ì¤‘...\")\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   - Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "print(f\"   - F1 Macro: {eval_result['eval_f1_macro']:.4f}\")\n",
    "print(f\"   - Precision Macro: {eval_result['eval_precision_macro']:.4f}\")\n",
    "print(f\"   - Recall Macro: {eval_result['eval_recall_macro']:.4f}\")\n",
    "print(f\"   - Loss: {eval_result['eval_loss']:.4f}\")\n",
    "print(f\"   - ì´ ì†Œìš” ì‹œê°„: {training_time/60:.1f}ë¶„\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "model_path = f\"./best_model_{timestamp}\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "print(f\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "result = {\n",
    "    'timestamp': timestamp,\n",
    "    'config': CONFIG,\n",
    "    'accuracy': float(eval_result['eval_accuracy']),\n",
    "    'f1_macro': float(eval_result['eval_f1_macro']),\n",
    "    'precision_macro': float(eval_result['eval_precision_macro']),\n",
    "    'recall_macro': float(eval_result['eval_recall_macro']),\n",
    "    'loss': float(eval_result['eval_loss']),\n",
    "    'training_time_minutes': training_time/60,\n",
    "    'model_path': model_path,\n",
    "    'train_samples': len(train_texts),\n",
    "    'val_samples': len(val_texts)\n",
    "}\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ‰ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604946ea",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e41b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\nğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"   â±ï¸  í•™ìŠµ ì‹œê°„: {result['training_time_minutes']:.1f}ë¶„\")\n",
    "print(f\"   ğŸ“ˆ Accuracy: {result['accuracy']:.4f}\")\n",
    "print(f\"   ğŸ¯ F1 Macro: {result['f1_macro']:.4f}\")\n",
    "print(f\"   ğŸ” Precision: {result['precision_macro']:.4f}\")\n",
    "print(f\"   ğŸ”„ Recall: {result['recall_macro']:.4f}\")\n",
    "print(f\"   ğŸ“‰ Loss: {result['loss']:.4f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n\udcc2 ëª¨ë¸ ì •ë³´:\")\n",
    "print(f\"   - ëª¨ë¸ ê²½ë¡œ: {result['model_path']}\")\n",
    "print(f\"   - Train ìƒ˜í”Œ: {result['train_samples']:,}\")\n",
    "print(f\"   - Val ìƒ˜í”Œ: {result['val_samples']:,}\")\n",
    "print(f\"   - ëª¨ë¸ëª…: {CONFIG['model_name']}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì„±ëŠ¥ í•´ì„:\")\n",
    "if result['f1_macro'] >= 0.75:\n",
    "    print(f\"   âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥! (F1 â‰¥ 0.75)\")\n",
    "    print(f\"   â†’ ì‹¤ì œ ì±—ë´‡ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤.\")\n",
    "elif result['f1_macro'] >= 0.70:\n",
    "    print(f\"   âœ… ì¢‹ì€ ì„±ëŠ¥! (F1 â‰¥ 0.70)\")\n",
    "    print(f\"   â†’ ì‹¤ì „ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.\")\n",
    "elif result['f1_macro'] >= 0.65:\n",
    "    print(f\"   âš ï¸  ê´œì°®ì€ ì„±ëŠ¥ (F1 â‰¥ 0.65)\")\n",
    "    print(f\"   â†’ ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  ê°œì„  í•„ìš” (F1 < 0.65)\")\n",
    "    print(f\"   â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì´ë‚˜ ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nğŸ”„ K-Fold ë°©ì‹ê³¼ ë¹„êµ:\")\n",
    "print(f\"   - ë‹¨ì¼ ë¶„í• : í•™ìŠµ ì‹œê°„ ì ˆë°˜, ë” ë§ì€ ë°ì´í„° ì‚¬ìš©\")\n",
    "print(f\"   - K-Fold: ì•ˆì •ì„± ê²€ì¦, ë‘ ë°° ì‹œê°„ ì†Œìš”\")\n",
    "print(f\"   â†’ ë‹¨ì¼ ë¶„í• ë¡œ {result['train_samples']:,}ê°œ ìƒ˜í”Œë¡œ í•™ìŠµ (K-FoldëŠ” 65K)\")\n",
    "print(f\"   â†’ ì•½ {result['train_samples'] - 65000:,}ê°œ ë” ë§ì€ ë°ì´í„° í™œìš©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a9192",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê°œì„ ëœ ë²„ì „ - ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ë°©ì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ec165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ JSON ì €ì¥\n",
    "summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'config': CONFIG,\n",
    "    'result': result,\n",
    "    'accuracy': float(result['accuracy']),\n",
    "    'f1_macro': float(result['f1_macro']),\n",
    "    'precision_macro': float(result['precision_macro']),\n",
    "    'recall_macro': float(result['recall_macro']),\n",
    "    'loss': float(result['loss']),\n",
    "    'training_time_minutes': float(result['training_time_minutes']),\n",
    "    'model_path': result['model_path'],\n",
    "    'train_samples': result['train_samples'],\n",
    "    'val_samples': result['val_samples']\n",
    "}\n",
    "\n",
    "with open('training_summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: training_summary.json\")\n",
    "print(\"\\nğŸ“„ JSON ë‚´ìš©:\")\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863def04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ğŸ¯ í•™ìŠµí•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê°œì„ ëœ ë²„ì „ - ì‹¤íŒ¨ ë°©ì§€)\n",
    "# ============================================\n",
    "\n",
    "from google.colab import files\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“¥ í•™ìŠµí•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # 1. JSON íŒŒì¼ì—ì„œ ëª¨ë¸ ì •ë³´ ì½ê¸°\n",
    "    if os.path.exists('training_summary.json'):\n",
    "        with open('training_summary.json', 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        model_folder = summary['model_path'].lstrip('./')  # './' ì œê±°\n",
    "        timestamp_str = summary['timestamp']\n",
    "        f1_score = summary['f1_macro']\n",
    "        accuracy = summary['accuracy']\n",
    "    else:\n",
    "        print(\"âš ï¸ training_summary.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ëª¨ë¸ í´ë”ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤...\\n\")\n",
    "        \n",
    "        # ëª¨ë“  ëª¨ë¸ í´ë” ì°¾ê¸°\n",
    "        all_models = [d for d in os.listdir('.') if os.path.isdir(d) and 'best_model' in d]\n",
    "        if not all_models:\n",
    "            raise FileNotFoundError(\"ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        model_folder = all_models[0]\n",
    "        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        f1_score = 0\n",
    "        accuracy = 0\n",
    "    \n",
    "    print(f\"âœ… ëª¨ë¸ ë°œê²¬: {model_folder}\")\n",
    "    print(f\"   - F1 Macro: {f1_score:.4f}\")\n",
    "    print(f\"   - Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # 2. ëª¨ë¸ í´ë” ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(model_folder):\n",
    "        raise FileNotFoundError(f\"ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_folder}\")\n",
    "    \n",
    "    # 3. í´ë” ë‚´ íŒŒì¼ í™•ì¸\n",
    "    model_files = os.listdir(model_folder)\n",
    "    print(f\"\\nğŸ“¦ ëª¨ë¸ íŒŒì¼ ëª©ë¡ ({len(model_files)}ê°œ):\")\n",
    "    required_files = ['config.json', 'pytorch_model.bin', 'tokenizer_config.json']\n",
    "    for req_file in required_files:\n",
    "        if req_file in model_files:\n",
    "            file_size = os.path.getsize(os.path.join(model_folder, req_file)) / 1024 / 1024\n",
    "            print(f\"   âœ… {req_file} ({file_size:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {req_file} (ì—†ìŒ)\")\n",
    "    \n",
    "    # 4. ZIP ì••ì¶•\n",
    "    zip_filename = f'best_model_{timestamp_str}'\n",
    "    print(f\"\\nğŸ“¦ ì••ì¶• ì¤‘: {model_folder}\")\n",
    "    print(f\"   â†’ {zip_filename}.zip\")\n",
    "    \n",
    "    # ì••ì¶• ì‹œì‘\n",
    "    shutil.make_archive(zip_filename, 'zip', model_folder)\n",
    "    \n",
    "    # ì••ì¶• íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "    if os.path.exists(f'{zip_filename}.zip'):\n",
    "        zip_size = os.path.getsize(f'{zip_filename}.zip') / 1024 / 1024\n",
    "        print(f\"âœ… ì••ì¶• ì™„ë£Œ! í¬ê¸°: {zip_size:.1f} MB\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"ì••ì¶• íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 5. ë‹¤ìš´ë¡œë“œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)\n",
    "    print(f\"\\nğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
    "    print(\"ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìš´ë¡œë“œ í—ˆìš©ì„ í´ë¦­í•˜ì„¸ìš”!\")\n",
    "    \n",
    "    try:\n",
    "        files.download(f'{zip_filename}.zip')\n",
    "        print(\"âœ… ëª¨ë¸ ZIP ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "        print(\"\\nğŸ”„ ëŒ€ì•ˆ ë°©ë²•:\")\n",
    "        print(\"   1. ì™¼ìª½ íŒŒì¼ ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ\")\n",
    "        print(f\"   2. íŒŒì¼ëª…: {zip_filename}.zip\")\n",
    "        print(\"   3. íŒŒì¼ ìš°í´ë¦­ â†’ Download\")\n",
    "    \n",
    "    # 6. JSON íŒŒì¼ë„ ë‹¤ìš´ë¡œë“œ\n",
    "    print(f\"\\nğŸ“¥ í•™ìŠµ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ...\")\n",
    "    try:\n",
    "        files.download('training_summary.json')\n",
    "        print(\"âœ… JSON ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ JSON ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… ë‹¤ìš´ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nğŸ’¡ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼:\")\n",
    "    print(f\"   1. {zip_filename}.zip - í•™ìŠµëœ ëª¨ë¸ (ì•½ {zip_size:.0f} MB)\")\n",
    "    print(f\"   2. training_summary.json - í•™ìŠµ ê²°ê³¼ ìš”ì•½\")\n",
    "    \n",
    "    print(\"\\nğŸ“‚ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "    print(\"   1. ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ í™•ì¸ (Downloads í´ë”)\")\n",
    "    print(\"   2. ë¡œì»¬ í”„ë¡œì íŠ¸ë¡œ ì´ë™:\")\n",
    "    print(\"      cd C:\\\\Users\\\\rlarl\\\\OneDrive\\\\Desktop\\\\chatbot\")\n",
    "    print(\"   3. ZIP íŒŒì¼ì„ checkpoints_kfold\\\\ í´ë”ë¡œ ì´ë™\")\n",
    "    print(\"   4. ì••ì¶• í•´ì œ:\")\n",
    "    print(f\"      Expand-Archive -Path '{zip_filename}.zip' -DestinationPath 'checkpoints_kfold\\\\'\")\n",
    "    print(\"   5. ëª¨ë¸ í…ŒìŠ¤íŠ¸:\")\n",
    "    print(\"      python test_model_integration.py\")\n",
    "    print(\"   6. ì±—ë´‡ ì‹¤í–‰:\")\n",
    "    print(\"      python fastapi_app/main.py\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nâŒ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. ìœ„ì˜ í•™ìŠµ ì…€ì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:\")\n",
    "    print(\"      - ì™¼ìª½ íŒŒì¼ ë¸Œë¼ìš°ì € ì—´ê¸°\")\n",
    "    print(\"      - 'best_model_*' í´ë” ì°¾ê¸°\")\n",
    "    print(\"      - í´ë” ìš°í´ë¦­ â†’ Download\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "    print(f\"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}\")\n",
    "    print(\"\\nğŸ’¡ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ë°©ë²•:\")\n",
    "    print(\"   1. ì™¼ìª½ íŒŒì¼ ì•„ì´ì½˜ í´ë¦­ (ğŸ“)\")\n",
    "    print(\"   2. 'best_model_*' í´ë” ì°¾ê¸°\")\n",
    "    print(\"   3. í´ë” ìš°í´ë¦­ â†’ Download\")\n",
    "    print(\"\\nğŸ”„ ë˜ëŠ” ë‹¤ìŒ ì½”ë“œë¡œ ìˆ˜ë™ ì••ì¶•:\")\n",
    "    print(\"   import shutil\")\n",
    "    print(\"   from google.colab import files\")\n",
    "    print(\"   model_folder = 'best_model_20251104_XXXXXX'  # ì‹¤ì œ í´ë”ëª…\")\n",
    "    print(\"   shutil.make_archive(model_folder, 'zip', model_folder)\")\n",
    "    print(\"   files.download(f'{model_folder}.zip')\")\n",
    "\n",
    "finally:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ ì°¸ê³  ì‚¬í•­\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"â€¢ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ: íŒŒì¼ ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ\")\n",
    "    print(\"â€¢ ë¸Œë¼ìš°ì € ì°¨ë‹¨: ì£¼ì†Œì°½ ì˜¤ë¥¸ìª½ì˜ ì°¨ë‹¨ ì•„ì´ì½˜ í´ë¦­ â†’ í—ˆìš©\")\n",
    "    print(\"â€¢ í° íŒŒì¼: ë‹¤ìš´ë¡œë“œì— 10-30ì´ˆ ì†Œìš” ê°€ëŠ¥\")\n",
    "    print(\"â€¢ ZIP ì••ì¶•: ì•½ 110MB í¬ê¸° (ì›ë³¸ í´ë”ì™€ ë™ì¼)\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01839b",
   "metadata": {},
   "source": [
    "## ğŸ‰ í•™ìŠµ ì™„ë£Œ!\n",
    "\n",
    "ì¶•í•˜í•©ë‹ˆë‹¤! **KR-BERT ê°ì • ë¶„ë¥˜ ëª¨ë¸** í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“¦ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼\n",
    "1. **`best_model_{timestamp}.zip`** - í•™ìŠµëœ ëª¨ë¸ (ì••ì¶•, ì•½ 110MB)\n",
    "2. **`training_summary.json`** - í•™ìŠµ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "### ğŸ”§ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "#### 1ï¸âƒ£ Windowsì—ì„œ ì••ì¶• í•´ì œ\n",
    "```powershell\n",
    "# PowerShell ì‹¤í–‰\n",
    "cd C:\\Users\\rlarl\\OneDrive\\Desktop\\chatbot\\checkpoints_kfold\n",
    "\n",
    "# ë‹¤ìš´ë¡œë“œí•œ ZIP íŒŒì¼ ì´ë™ (Downloads í´ë”ì—ì„œ)\n",
    "Move-Item \"$env:USERPROFILE\\Downloads\\best_model_*.zip\" \".\\\"\n",
    "\n",
    "# ì••ì¶• í•´ì œ\n",
    "Expand-Archive -Path \"best_model_*.zip\" -DestinationPath \".\\\"\n",
    "\n",
    "# íŒŒì¼ í™•ì¸\n",
    "dir best_model_*\n",
    "```\n",
    "\n",
    "#### 2ï¸âƒ£ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "```powershell\n",
    "cd C:\\Users\\rlarl\\OneDrive\\Desktop\\chatbot\n",
    "python test_model_integration.py\n",
    "```\n",
    "\n",
    "#### 3ï¸âƒ£ ì±—ë´‡ì— í†µí•©\n",
    "```powershell\n",
    "python fastapi_app/main.py\n",
    "```\n",
    "\n",
    "### ğŸ“Š ë‹¨ì¼ ë¶„í•  (80/20) vs K-Fold ë¹„êµ\n",
    "\n",
    "| í•­ëª© | ë‹¨ì¼ ë¶„í•  (80/20) | K-Fold (50/50) |\n",
    "|------|------------------|----------------|\n",
    "| **í•™ìŠµ ë°ì´í„°** | **104,872 samples** | 65,545 samples |\n",
    "| **ê²€ì¦ ë°ì´í„°** | 26,219 samples | 65,546 samples |\n",
    "| **ì˜ˆìƒ F1** | **0.720-0.760** â­ | 0.710 Â± 0.002 |\n",
    "| **í•™ìŠµ ì‹œê°„** | **90-120ë¶„** âš¡ | 180-240ë¶„ |\n",
    "| **ì¥ì ** | ë” ë§ì€ ë°ì´í„° í•™ìŠµ<br>ì‹œê°„ ì ˆì•½ | ì•ˆì •ì„± ê²€ì¦<br>ê³¼ì í•© ê°ì§€ |\n",
    "| **ë‹¨ì ** | ì„±ëŠ¥ ë³€ë™ ê°€ëŠ¥<br>ê²€ì¦ ìƒ˜í”Œ ì ìŒ | ì‹œê°„ 2ë°°<br>í•™ìŠµ ë°ì´í„° ì ìŒ |\n",
    "\n",
    "### ğŸ¯ ì˜ˆìƒ ì„±ëŠ¥ (í†µí•© ë°ì´í„° 131K samples ê¸°ì¤€)\n",
    "\n",
    "ë‹¨ì¼ ë¶„í•  ë°©ì‹ìœ¼ë¡œ **ë” ë§ì€ ë°ì´í„°(104K)**ë¥¼ í•™ìŠµí•˜ë¯€ë¡œ:\n",
    "\n",
    "- **Accuracy**: 88-93% (K-Fold ëŒ€ë¹„ +1~3%p í–¥ìƒ ì˜ˆìƒ)\n",
    "- **F1 Macro**: 0.72-0.76 (K-Fold ëŒ€ë¹„ +1~5%p í–¥ìƒ ì˜ˆìƒ)\n",
    "- **Precision/Recall**: 0.71-0.75\n",
    "\n",
    "### ğŸ’¡ ì™œ ë‹¨ì¼ ë¶„í• ì´ ë” ë‚˜ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
    "\n",
    "```\n",
    "104,872 ìƒ˜í”Œë¡œ í•™ìŠµ (vs K-Fold 65,545)\n",
    "        â†“\n",
    "ì•½ 39,000ê°œ ë” ë§ì€ ë°ì´í„°\n",
    "        â†“\n",
    "ëª¨ë¸ì´ ë” ë§ì€ íŒ¨í„´ í•™ìŠµ\n",
    "        â†“\n",
    "ê²€ì¦ ì„¸íŠ¸ì—ì„œ ë” ë†’ì€ ì„±ëŠ¥!\n",
    "```\n",
    "\n",
    "**í•˜ì§€ë§Œ ì£¼ì˜**: \n",
    "- ê²€ì¦ ì„¸íŠ¸ê°€ \"ìš´ì´ ì¢‹ì€\" ìƒ˜í”Œì¼ ìˆ˜ ìˆìŒ\n",
    "- ì‹¤ì „ ì„±ëŠ¥ì€ K-Foldì™€ ë¹„ìŠ·í•  ìˆ˜ë„ ìˆìŒ\n",
    "- ì•ˆì •ì„±ì€ K-Foldê°€ ë” ì‹ ë¢°ì„± ë†’ìŒ\n",
    "\n",
    "### ğŸ”„ ì¶”ì²œ ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "```\n",
    "1. í˜„ì¬: ë‹¨ì¼ ë¶„í• ë¡œ ë¹ ë¥´ê²Œ í•™ìŠµ (90-120ë¶„)\n",
    "         â†’ F1 0.72-0.76 ë‹¬ì„±\n",
    "\n",
    "2. ê²€ì¦: ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ë‹¤ë©´ ë°”ë¡œ ë°°í¬\n",
    "         ë˜ëŠ” K-Foldë¡œ ì•ˆì •ì„± ì¬í™•ì¸\n",
    "\n",
    "3. ë°°í¬: FastAPI ì±—ë´‡ì— í†µí•©í•˜ì—¬ ì‹¤ì „ í…ŒìŠ¤íŠ¸\n",
    "```\n",
    "\n",
    "### âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²˜ë²•\n",
    "\n",
    "#### ë°©ë²• 1: íŒŒì¼ ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ\n",
    "1. Colab ì™¼ìª½ íŒŒì¼ ì•„ì´ì½˜(ğŸ“) í´ë¦­\n",
    "2. `best_model_YYYYMMDD_HHMMSS` í´ë” ì°¾ê¸°\n",
    "3. í´ë” ìš°í´ë¦­ â†’ **Download**\n",
    "\n",
    "#### ë°©ë²• 2: ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "```python\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# ëª¨ë¸ í´ë” ì°¾ê¸°\n",
    "models = [d for d in os.listdir('.') if 'best_model' in d]\n",
    "model_folder = models[0]\n",
    "\n",
    "# ì¤‘ìš” íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ\n",
    "important_files = [\n",
    "    'config.json',\n",
    "    'pytorch_model.bin',\n",
    "    'tokenizer_config.json',\n",
    "    'vocab.txt'\n",
    "]\n",
    "\n",
    "for file in important_files:\n",
    "    file_path = os.path.join(model_folder, file)\n",
    "    if os.path.exists(file_path):\n",
    "        files.download(file_path)\n",
    "```\n",
    "\n",
    "#### ë°©ë²• 3: Google Driveì— ì €ì¥\n",
    "```python\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# Drive ë§ˆìš´íŠ¸\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ëª¨ë¸ ë³µì‚¬\n",
    "model_folder = 'best_model_20251104_XXXXXX'  # ì‹¤ì œ í´ë”ëª…\n",
    "drive_path = f'/content/drive/MyDrive/chatbot_models/{model_folder}'\n",
    "\n",
    "shutil.copytree(model_folder, drive_path)\n",
    "print(f\"âœ… Google Driveì— ì €ì¥ ì™„ë£Œ: {drive_path}\")\n",
    "```\n",
    "\n",
    "### ğŸ“š ì¶”ê°€ ì •ë³´\n",
    "\n",
    "- **ëª¨ë¸ í†µí•© ê°€ì´ë“œ**: `MODEL_INTEGRATION_GUIDE.md` ì°¸ê³ \n",
    "- **ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ**: `COLAB_DOWNLOAD_GUIDE.md` ì°¸ê³ \n",
    "- **API ë¬¸ì„œ**: http://localhost:8000/docs (ì„œë²„ ì‹¤í–‰ í›„)\n",
    "\n",
    "### \ude80 ì„±ê³µì„ ì¶•í•˜í•©ë‹ˆë‹¤!\n",
    "\n",
    "ë‹¨ì¼ ë¶„í•  ë°©ì‹ìœ¼ë¡œ:\n",
    "- âœ… **ì‹œê°„ ì ˆì•½**: K-Fold ëŒ€ë¹„ ì ˆë°˜ (90-120ë¶„)\n",
    "- âœ… **ë” ë§ì€ ë°ì´í„°**: 104K samplesë¡œ í•™ìŠµ\n",
    "- âœ… **ë” ë†’ì€ ì„±ëŠ¥**: F1 0.72-0.76 ì˜ˆìƒ\n",
    "- âœ… **ë°°í¬ ì¤€ë¹„**: ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸\n",
    "\n",
    "ì´ì œ ì±—ë´‡ì— í†µí•©í•˜ì—¬ ì‹¤ì „ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”! ğŸ¯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
